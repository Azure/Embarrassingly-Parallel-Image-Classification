{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image set preparation\n",
    "\n",
    "This notebook illustrates how the image set used for training and evaluation was generated from freely available aerial imagery and land use datasets.\n",
    "\n",
    "## Outline\n",
    "- [Source data](#sourcedata)\n",
    "   - [National Land Cover Database](#nlcd)\n",
    "   - [National Agriculture Imagery Program](#naip)\n",
    "- [Preparing an Azure Data Science Virtual Machine for image extraction](#dsvm)\n",
    "   - [Provisioning and accessing the DSVM](#provision)\n",
    "   - [Installing Python packages and supporting software](#install)\n",
    "   - [Downloading input data locally](#download)\n",
    "- [Producing image sets for training and evaluation](#production)\n",
    "   - [Converting NAIP images from MrSID to GeoTIFF](#conversion)\n",
    "   - [Add tiling for fast data extraction](#tiling)\n",
    "   - [Find a lat-lon bounding box for the region](#box)\n",
    "   - [Get the approximate dimensions of the bounding box in meters](#meters)\n",
    "   - [Finding regions with consistent land use class](#consistent)\n",
    "   - [Extract and save images for tiles of interest](#extraction)\n",
    "   - [Automating extraction from multiple counties](#automation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sourcedata\"></a>\n",
    "## Source data\n",
    "\n",
    "<a name=\"naip\"></a>\n",
    "### National Agriculture Imagery Program\n",
    "\n",
    "The US [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/index) is run by the [US Department of Agriculture](https://www.usda.gov/)'s [Farm Service Agency](https://www.fsa.usda.gov/). NAIP images are provided within one month of image collection, in natural (RGB) color with 1-meter ground sample distance. In this tutorial, we use Compressed County Mosaics obtained from the [Geospatial Data Gateway](https://gdg.sc.egov.usda.gov/).\n",
    "\n",
    "<a name=\"nlcd\"></a>\n",
    "### National Land Cover Database\n",
    "\n",
    "The US [National Land Cover Database](https://www.mrlc.gov/nlcd2011.php) (NLCD), maintained by the [Multi-Resolution Land Characteristic Consortium](https://www.mrlc.gov/), provides land use labels at 30-meter spatial resolution for the United States. The [sixteen land use classes](https://www.mrlc.gov/nlcd11_leg.php) in the NLCD are organized hierarchically into major (Developed, Forested, Planted/Cultivated, &c.) and minor (e.g. Deciduous, Evergreen, or Mixed Forest) categories. Classifications are based largely on seasonally-collected satellite imagery (including data collected outside the visual spectrum). Because of the extensive post-processing required to prepare this dataset, new versions are published approximately every five years, often with a multi-year delay between data collection and publication. For this project, we use the [NLCD 2011 Land Cover](https://www.mrlc.gov/nlcd11_data.php) dataset.\n",
    "\n",
    "For more information on the NLCD, please see the following publication:\n",
    "\n",
    "Homer, C.G., Dewitz, J.A., Yang, L., Jin, S., Danielson, P., Xian, G., Coulston, J., Herold, N.D., Wickham, J.D., and Megown, K., 2015, [Completion of the 2011 National Land Cover Database for the conterminous United States - Representing a decade of land cover change information](http://bit.ly/1K7WjO3). Photogrammetric Engineering and Remote Sensing, v. 81, no. 5, p. 345-354 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"dsvm\"></a>\n",
    "## Preparing an Azure Data Science Virtual Machine for image extraction\n",
    "\n",
    "For reproducibility and brevity, this walkthrough describes how to set up an [Azure Data Science Virtual Machine](https://azure.microsoft.com/en-us/marketplace/partners/microsoft-ads/standard-data-science-vm/) for image extraction. It is very likely that the steps below can be adapted for your own computer.\n",
    "\n",
    "<a name=\"provision\"></a>\n",
    "### Provisioning and accessing the DSVM\n",
    "\n",
    "To provision a Data Science Virtual Machine, you will need an [Azure account](https://azure.microsoft.com/en-us/free/). Click the \"Deploy to Azure\" button to begin the process:\n",
    "\n",
    "<a href=\"https://azuredeploy.net/?repository=https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Data-Science-Virtual-Machine/Windows\">![Deploy to Azure](https://camo.githubusercontent.com/a941ea1d057c4efc2dcc0a680f43c97728ec0bd8/687474703a2f2f617a7572656465706c6f792e6e65742f6465706c6f79627574746f6e2e737667)</a>\n",
    "\n",
    "After logging in, you can select a name for your VM, login information, and [VM size](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-sizes#a-series). We chose an \"A4\" VM because of the large temporary hard disk space included. (Aerial imagery data for some counties can take up >100 GB when decompressed and converted to GeoTIFF format.) If your hard disk requirements are smaller, you may prefer a VM with a solid-state drive for faster file I/O. Confirm your selections to begin deployment.\n",
    "\n",
    "After deployment concludes, navigate to the VM's overview pane in [Azure Portal](https://portal.azure.com) by e.g. searching for the VM or resource name. Click the \"Connect\" button along the top of the pane to download a Remote Desktop connection file. Once the download completes, double-click the file to connect to your VM.\n",
    "\n",
    "Note that your VM will continue to run even after you disconnect from Remote Desktop. You can stop or delete the VM at any time from [Azure Portal](https://portal.azure.com).\n",
    "\n",
    "<a name=\"install\"></a>\n",
    "### Installing Python packages and supporting software\n",
    "\n",
    "#### LizardTech's GeoExpress Command Line Applications\n",
    "NAIP imagery provided in [MrSID](https://en.wikipedia.org/wiki/MrSID) format: we will convert them to GeoTIFF format using LizardTech's free [GeoExpress Command Line Applications](https://www.lizardtech.com/gis-tools/tools-and-utilities). After downloading and decompressing the archive on your VM, copy the files to a permanent directory of your choice. Add the path to the binary file `mrsidgeodecode` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mrsidgeodecode_path = 'C:\\\\Program Files\\\\GeoExpressCLUtils-9.5.0.4326-win64\\\\bin\\\\mrsidgeodecode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python packages\n",
    "To read the resulting GeoTIFF, we will use the GDAL package from within Python. As of this writing, Christoph Gohlke's [Unofficial Windows Binaries for Python Extension Packages](http://www.lfd.uci.edu/~gohlke/pythonlibs/) provide the easiest means to install the GDAL package, binaries, and library. We downloaded the Python 3.5 wheels for the following packages from Christoph's site for this walkthrough:\n",
    "- [GDAL](http://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal)\n",
    "- [Basemap](http://www.lfd.uci.edu/~gohlke/pythonlibs/#basemap)\n",
    "- [Fiona](http://www.lfd.uci.edu/~gohlke/pythonlibs/#fiona)\n",
    "- [Shapely](http://www.lfd.uci.edu/~gohlke/pythonlibs/#shapely)\n",
    "\n",
    "To install these wheels:\n",
    "1. Launch an Anaconda Prompt\n",
    "1. Activate the Python 3.5 environment pre-installed on your DSVM using the following command:\n",
    "\n",
    "  `activate py35`<br/><br/>\n",
    "  \n",
    "1. Install each wheel (`[wheel filename]`) with the following command:\n",
    "\n",
    "  `pip install [wheel filename]`\n",
    "\n",
    "<a name=\"download\"></a>\n",
    "### Downloading input data locally\n",
    "\n",
    "#### National Land Cover Database\n",
    "\n",
    "[Download](https://www.mrlc.gov/nlcd11_data.php) the compressed 2011 National Land Cover Database file (1.1 GB) and extract its contents to a folder of your choice (we used D:\\nlcd). Store the filepath with a `.img` extension by editing and executing the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlcd_filepath = 'D:\\\\nlcd\\\\nlcd_2011_landcover_2011_edition_2014_10_10.img'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### National Agriculture Imagery Program\n",
    "\n",
    "As of this writing (1/31/2017), an unplanned outage complicates access to NAIP Compressed County Mosaics via the [Geospatial Data Gateway](https://gdg.sc.egov.usda.gov/). We have mirrored [a sample file](https://mawahstorage.blob.core.windows.net/aerialimageclassification/naipsample/ortho_imagery_NAIPM16_ma017_3344056_01.zip) (Middlesex County, MA 2016 data) for your convenience in following this tutorial. (You can make additional county requests using the email address provided on the gateway.) Download and decompress the file, storing the folder path in the following variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naip_dir = 'D:\\\\naip\\\\ortho_imagery_NAIPM16_ma017_3344056_01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"production\"></a>\n",
    "## Producing image sets for training and evaluation\n",
    "\n",
    "<a name=\"conversion\"></a>\n",
    "### Converting NAIP images from MrSID to GeoTIFF\n",
    "\n",
    "We will use LizardTech's GeoExpress Command Line Application `mrsidgeodecode` to convert the aerial imagery data from MrSID format to GeoTIFF. Expect a >10-fold expansion in file size during conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "filename_base = None\n",
    "for filename in os.listdir(naip_dir):\n",
    "    if filename.endswith('.sid'):\n",
    "        filename_base = filename.split('.sid')[0]\n",
    "        break\n",
    "if filename_base == None:\n",
    "    raise Exception(\"Couldn't find the MrSID file in {}\".format(naip_dir))\n",
    "\n",
    "geodecode_command = [mrsidgeodecode_path, '-wf',\n",
    "                     '-i', os.path.join(naip_dir, '{}.sid'.format(filename_base)),\n",
    "                     '-o', os.path.join(naip_dir, '{}.tif'.format(filename_base))]\n",
    "results = shutil.run(geodecode_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tiling\"></a>\n",
    "### Add tiling for fast data extraction\n",
    "\n",
    "To speed up image extraction images from arbitrary regions of the GeoTIFF, we add tiling to the image. Since we must write the tiled image before deleting the untiled version, we effectively double our disk space usage at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdal_command = ['C:\\\\Anaconda\\\\envs\\\\py35\\\\Lib\\\\site-packages\\\\osgeo\\\\gdal_translate',\n",
    "            '-co', 'TILED=YES',\n",
    "            os.path.join(tmp_dir, '{}.tif'.format(filename_base)),\n",
    "            os.path.join(tmp_dir, '{}_tiled.tif'.format(filename_base))]\n",
    "results = run(gdal_command)\n",
    "os.remove(os.path.join(tmp_dir, '{}.tif'.format(filename_base)))\n",
    "\n",
    "naip_filepath = os.path.join(tmp_dir, '{}_tiled.tif'.format(filename_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"box\"></a>\n",
    "### Find a lat-lon bounding box for the region\n",
    "\n",
    "We now find the lat-lon bounding box of the NAIP GeoTIFF. Some locations inside this bounding box will not have any available data, but the box is still useful for first-order estimation of the usable region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from gdalconst import *\n",
    "import osr\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from collections import namedtuple\n",
    "\n",
    "LatLonBounds = namedtuple('LatLonBounds', ['llcrnrlat', 'llcrnrlon', 'urcrnrlat', 'urcrnrlon'])\n",
    "\n",
    "def get_region_bounds(naip_filepath):\n",
    "    ''' Finds a bounding box for the NAIP GeoTIFF in lat/lon '''\n",
    "    naip_image = gdal.Open(naip_filepath, GA_ReadOnly)\n",
    "    naip_proj = osr.SpatialReference()\n",
    "    naip_proj.ImportFromWkt(naip_image.GetProjection())\n",
    "    naip_ulcrnrx, naip_xstep, _, naip_ulcrnry, _, naip_ystep = naip_image.GetGeoTransform()\n",
    "\n",
    "    world_map = Basemap(lat_0 = 0,\n",
    "                        lon_0 = 0,\n",
    "                        llcrnrlat=-90, urcrnrlat=90,\n",
    "                        llcrnrlon=-180, urcrnrlon=180,\n",
    "                        resolution='c', projection='stere')\n",
    "    world_proj = osr.SpatialReference()\n",
    "    world_proj.ImportFromProj4(world_map.proj4string)\n",
    "    ct_to_world = osr.CoordinateTransformation(naip_proj, world_proj)\n",
    "    \n",
    "    lats = []\n",
    "    lons = []\n",
    "    for corner_x, corner_y in [(naip_ulcrnrx, naip_ulcrnry),\n",
    "                               (naip_ulcrnrx, naip_ulcrnry + naip_image.RasterYSize * naip_ystep),\n",
    "                               (naip_ulcrnrx + naip_image.RasterXSize * naip_xstep,\n",
    "                                naip_ulcrnry + naip_image.RasterYSize * naip_ystep),\n",
    "                               (naip_ulcrnrx + naip_image.RasterXSize * naip_xstep, naip_ulcrnry)]:\n",
    "        xpos, ypos, _ = ct_to_world.TransformPoint(corner_x, corner_y)\n",
    "        lon, lat = world_map(xpos, ypos, inverse=True)\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "\n",
    "    return(LatLonBounds(llcrnrlat=min(lats),\n",
    "                        llcrnrlon=min(lons),\n",
    "                        urcrnrlat=max(lats),\n",
    "                        urcrnrlon=max(lons)))\n",
    "\n",
    "region_bounds = get_bounding_box(naip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"meters\"></a>\n",
    "### Get the approximate dimensions of the bounding box in meters\n",
    "\n",
    "Here we approximate the width/height of the bounding box in meters, using the fact that latitude does not change substantially on the county scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RegionSize = namedtuple('RegionSize', ['width', 'height'])  # in meters!\n",
    "import numpy as np\n",
    "\n",
    "def get_approx_region_size(region_bounds):\n",
    "    ''' Returns the region width (at mid-lat) and height in meters'''\n",
    "    mid_lat_radians = (region_bounds.llcrnrlat + region_bounds.urcrnrlat) * \\\n",
    "                      (np.pi / 360)\n",
    "    earth_circumference = 6.371E6 * 2 * np.pi # in meters\n",
    "    region_middle_width_meters = (region_bounds.urcrnrlon - region_bounds.llcrnrlon) * \\\n",
    "                                 earth_circumference * np.cos(mid_lat_radians) / (360)\n",
    "    region_height_meters = (region_bounds.urcrnrlat - region_bounds.llcrnrlat) * \\\n",
    "                           earth_circumference / (360)\n",
    "    return(RegionSize(region_middle_width_meters, region_height_meters))\n",
    "\n",
    "approx_region_size = get_approx_region_size(region_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"consistent\"></a>\n",
    "### Finding tiles with consistent land use class\n",
    "\n",
    "We will extract images of small regions (\"tiles\") and corresponding labels to use in training or evaluation. ResNet DNNs are traditionally trained with 224 px x 224 px images: this sets our minimum tile size at 224 meters x 224 meters (because our aerial imagery has approx. 1 meter resolution).\n",
    "\n",
    "Tiles that lie at the boundary of two or more land uses -- e.g., the edge of a forest or a shoreline -- may cause confusion during model training and evaluation. We chose tiles that are \"reasonably homeogeneous\" in land use class by confirming that land use type is consistent at nine regularly-spaced interior points. (We found through experimentation that requiring complete homogeneity limited our dataset size and increased the processing time substantially.)\n",
    "\n",
    "#### Define helper functions\n",
    "\n",
    "The function below defines a point labeler that we will use for tile selection. At the same time, we define an image extractor that we will use later in the tutorial. (Both functions require a coordinate transform from lat-lon to GeoTIFF-specific coordinates; defining them together keeps things succinct.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def create_helper_functions(region_bounds, nlcd_filepath, naip_filepath):\n",
    "    ''' Makes helper functions to label points (NLCD) and extract tiles (NAIP) '''\n",
    "    nlcd_image = gdal.Open(nlcd_filepath, GA_ReadOnly)\n",
    "    nlcd_proj = osr.SpatialReference()\n",
    "    nlcd_proj.ImportFromWkt(nlcd_image.GetProjection())\n",
    "    nlcd_ulcrnrx, nlcd_xstep, _, nlcd_ulcrnry, _, nlcd_ystep = nlcd_image.GetGeoTransform()\n",
    "    \n",
    "    naip_image = gdal.Open(naip_filepath, GA_ReadOnly)\n",
    "    naip_proj = osr.SpatialReference()\n",
    "    naip_proj.ImportFromWkt(naip_image.GetProjection())\n",
    "    naip_ulcrnrx, naip_xstep, _, naip_ulcrnry, _, naip_ystep = naip_image.GetGeoTransform()\n",
    "    \n",
    "    region_map = Basemap(lat_0 = (region_bounds.llcrnrlat + region_bounds.urcrnrlat)/2,\n",
    "                         lon_0 = (region_bounds.llcrnrlon + region_bounds.urcrnrlon)/2,\n",
    "                         llcrnrlat=region_bounds.llcrnrlat,\n",
    "                         llcrnrlon=region_bounds.llcrnrlon,\n",
    "                         urcrnrlat=region_bounds.urcrnrlat,\n",
    "                         urcrnrlon=region_bounds.urcrnrlon,\n",
    "                         resolution='c',\n",
    "                         projection='stere')\n",
    "    \n",
    "    region_proj = osr.SpatialReference()\n",
    "    region_proj.ImportFromProj4(region_map.proj4string)\n",
    "    ct_to_nlcd = osr.CoordinateTransformation(region_proj, nlcd_proj)\n",
    "    ct_to_naip = osr.CoordinateTransformation(region_proj, naip_proj)\n",
    "    \n",
    "    region_shapes = []\n",
    "    for i in fiona.open('{}.shp'.format(naip_filepath.split('_tiled.')[0])):\n",
    "        region_shapes.append(shape(i['geometry']))\n",
    "\n",
    "    def get_nlcd_label(point):\n",
    "        ''' Project lat/lon point to NLCD GeoTIFF; return label of that point '''\n",
    "        basemap_coords = region_map(point.lon, point.lat)  # NB unusual argument order\n",
    "        x, y, _ = [int(i) for i in ct_to_nlcd.TransformPoint(*basemap_coords)]\n",
    "        xoff = int(round((x - nlcd_ulcrnrx) / nlcd_xstep))\n",
    "        yoff = int(round((y - nlcd_ulcrnry) / nlcd_ystep))\n",
    "        label = int(nlcd_image.ReadAsArray(xoff=xoff, yoff=yoff, xsize=1, ysize=1))\n",
    "        return(label)\n",
    "    \n",
    "    def complete_intersection(xx, yy):\n",
    "        ''' Check whether a tile lies completely within the region's shapefile '''\n",
    "        tile_shape = shape({'type': 'Polygon',\n",
    "                            'coordinates': [[(xx[0, 0], yy[0, 0]),\n",
    "                                             (xx[-1, 0], yy[-1, 0]),\n",
    "                                             (xx[-1, -1], yy[-1, -1]),\n",
    "                                             (xx[0, -1], yy[0, -1])]]})\n",
    "        tile_area = tile_shape.area\n",
    "        intersection_area = 0.0\n",
    "        for region_shape in region_shapes:\n",
    "            if region_shape.intersects(tile_shape):\n",
    "                intersection_area += region_shape.intersection(tile_shape).area\n",
    "        if abs(tile_area - intersection_area) < 1.0:\n",
    "            return(True)\n",
    "        else:\n",
    "            return(False)\n",
    "        \n",
    "    def get_naip_tile(tile_bounds, tile_size):\n",
    "        ''' Check that tile lies within county bounds; if so, extract its image '''\n",
    "        \n",
    "        # Transform tile bounds in lat/lon to NAIP projection coordinates\n",
    "        xmax, ymax = region_map(tile_bounds.urcrnrlon, tile_bounds.urcrnrlat)\n",
    "        xmin, ymin = region_map(tile_bounds.llcrnrlon, tile_bounds.llcrnrlat)\n",
    "        xstep = (xmax - xmin) / tile_size.width\n",
    "        ystep = (ymax - ymin) / tile_size.height\n",
    "\n",
    "        grid = np.mgrid[xmin:xmax:tile_size.width * 1j, ymin:ymax:tile_size.height * 1j]\n",
    "        shape = grid[0, :, :].shape\n",
    "        size = grid[0, :, :].size\n",
    "        xy_target = np.array(ct_to_naip.TransformPoints(grid.reshape(2, size).T))\n",
    "        xx = xy_target[:,0].reshape(shape)\n",
    "        yy = xy_target[:,1].reshape(shape)\n",
    "        \n",
    "        # Check that the requested tile does not lie at the region boundary\n",
    "        if not complete_intersection(xx, yy):\n",
    "            return(None)\n",
    "        \n",
    "        # Extract rectangle from NAIP GeoTIFF containing superset of needed points\n",
    "        xoff = int(round((xx.min() - naip_ulcrnrx) / naip_xstep))\n",
    "        yoff = int(round((yy.max() - naip_ulcrnry) / naip_ystep))\n",
    "        xsize_to_use = int(np.ceil((xx.max() - xx.min())/np.abs(naip_xstep))) + 1\n",
    "        ysize_to_use = int(np.ceil((yy.max() - yy.min())/np.abs(naip_ystep))) + 1\n",
    "        data = naip_image.ReadAsArray(xoff=xoff,\n",
    "                                      yoff=yoff,\n",
    "                                      xsize=xsize_to_use,\n",
    "                                      ysize=ysize_to_use)        \n",
    "        # Map the pixels of interest in NAIP GeoTIFF to the tile (might involve rotation or scaling)\n",
    "        image = np.zeros((xx.shape[1], xx.shape[0], 3)).astype(int)  # rows are height, cols are width, third dim is color\n",
    "        \n",
    "        try:\n",
    "            for i in range(xx.shape[0]):\n",
    "                for j in range(xx.shape[1]):\n",
    "                    x_idx = int(round((xx[i,j] - naip_ulcrnrx) / naip_xstep)) - xoff\n",
    "                    y_idx = int(round((yy[i,j] - naip_ulcrnry) / naip_ystep)) - yoff\n",
    "                    image[xx.shape[1] - j - 1, i, :] = data[:, y_idx, x_idx]\n",
    "        except TypeError as e:\n",
    "            # The following can occur if our pixel superset request exceeds the GeoTIFF's bounds\n",
    "            return(None)\n",
    "                \n",
    "        image = Image.fromarray(image.astype('uint8'))\n",
    "        return(image)\n",
    "    \n",
    "    return(get_nlcd_label, get_naip_tile)\n",
    "get_nlcd_label, get_naip_tile = create_helper_functions(region_bounds, nlcd_filepath, naip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tile selection\n",
    "\n",
    "We form a rectangular grid of candidate tiles spanning as much of the (approximated-as-rectangular) bounding box as possible. Tiles that have \"reasonably homogeneous\" land use classification are retained for image extraction in the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LatLonPosition = namedtuple('LatLonPosition', ['lat', 'lon'])\n",
    "Tile = namedtuple('Tile', ['bounds', 'label'])\n",
    "\n",
    "def find_tiles_with_consistent_labels(region_bounds, region_size, tile_size):\n",
    "    ''' Find tiles for which nine grid points all have the same label '''\n",
    "    tiles_wide = int(np.floor(region_size.width / tile_size.width))\n",
    "    tiles_tall = int(np.floor(region_size.height / tile_size.height))\n",
    "    tile_width = (region_bounds.urcrnrlon - region_bounds.llcrnrlon) / (region_size.width / tile_size.width)\n",
    "    tile_height = (region_bounds.urcrnrlat - region_bounds.llcrnrlat) / (region_size.height / tile_size.height)\n",
    "    \n",
    "    current_lat = region_bounds.llcrnrlat\n",
    "    current_lon = region_bounds.llcrnrlon\n",
    "    \n",
    "    tiles_to_use = []\n",
    "    for i in range(tiles_tall):\n",
    "        for j in range(tiles_wide):\n",
    "            try:\n",
    "                labels = []\n",
    "                for k in range(3):\n",
    "                    for ell in range(3):\n",
    "                        labels.append(get_nlcd_label(LatLonPosition(lat=current_lat + tile_width * (1 + 2*k) / 6,\n",
    "                                                                    lon=current_lon + tile_height * (1 + 2*ell) / 6)))\n",
    "                num_matching = np.sum(np.array(labels) == labels[4])\n",
    "                if (num_matching == 9) and (labels[4] > 10):\n",
    "                    bounds = LatLonBounds(llcrnrlat=current_lat,\n",
    "                                          llcrnrlon=current_lon,\n",
    "                                          urcrnrlat=current_lat + tile_height,\n",
    "                                          urcrnrlon=current_lon + tile_width)\n",
    "                    tiles_to_use.append(Tile(bounds=bounds,\n",
    "                                             label=labels[4]))\n",
    "            except KeyError:\n",
    "                pass\n",
    "            current_lon += tile_width\n",
    "        current_lon = region_bounds.llcrnrlon\n",
    "        current_lat += tile_height\n",
    "    return(tiles_to_use)\n",
    "\n",
    "tiles = find_tiles_with_consistent_labels(region_bounds, approx_region_size, tile_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"extraction\"></a>\n",
    "### Extract and save images for tiles of interest\n",
    "\n",
    "The most time-consuming step is the extraction of images from the GeoTIFF. We use a helper function defined earlier, `naip_get_tile`, to check that the tile lies entirely inside the county shapefile and, if so, return the extracted image. Images are sorted into directories based on land use class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def extract_tiles(tiles, dest_folder):\n",
    "    ''' Coordinates saving tile data, including extracted images and CSV descriptions '''\n",
    "    my_region_id = uuid.uuid4()\n",
    "    if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "        \n",
    "    tile_descriptions = []\n",
    "    for i, tile in enumerate(tiles):\n",
    "        tile_image = get_naip_tile(tile.bounds, tile_size)\n",
    "        if (tile_image is None):\n",
    "            continue  # tile did not lie entirely within the county boundary (at least partially blank)\n",
    "        my_directory = os.path.join(dest_folder, '{:02d}'.format(tile.label))\n",
    "        my_filename = os.path.join(my_directory, '{}.png'.format(i))\n",
    "        if not os.path.exists(my_directory):\n",
    "            os.makedirs(my_directory)\n",
    "        tile_image.save(my_filename, 'PNG')\n",
    "    return\n",
    "\n",
    "extract_tiles(tiles, os.path.join(tmp_dir, filename_base))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
