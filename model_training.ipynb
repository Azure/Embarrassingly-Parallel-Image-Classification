{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNTK and TensorFlow models for image classification\n",
    "\n",
    "## Outline\n",
    "- [Provision an Azure N-Series GPU Deep Learning VM](#provision)\n",
    "- [Microsoft Cognitive Toolkit](#cntk)\n",
    "- [TensorFlow](#tensorflow)\n",
    "   - [Training script](#tfscript)\n",
    "   - [Model](#tfmodel)\n",
    "   - [Running the training script](#tfrun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"provision\"></a>\n",
    "## Provision an Azure N-Series GPU Deep Learning VM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a \"Deep Learning toolkit for the DSVM\" resource in a region that offers GPU VMs, such as East US. As of this writing (1/19), the DSVM deploys with CNTK 2.0.\n",
    "\n",
    "### Connecting to the VM by remote desktop\n",
    "\n",
    "To use remote desktop, click \"Connect\" on the VM's main pane to download an RDP file. When accessing, make sure that you specify the \"domain\" (VM name) as well as your username, e.g. \"mawahgpudsvm\\mawah\", so that the connection doesn't attempt to use your Microsoft domain.\n",
    "\n",
    "### Clone/download the contents of this repo\n",
    "\n",
    "Download the contents of this repo and copy the contents of the `tf` and `cntk` subfolders to appropriate locations. We have used locations on the temporary drive, e.g. `D:\\tf` and `D:\\cntk`.\n",
    "\n",
    "### Downloading the training and evaluation set locally\n",
    "\n",
    "During image set preparation, a training image set and descriptive files were created for use with CNTK and TensorFlow. Transfer these files to the GPU VM and store in an appropriate location. (We have used the `D:\\combined\\train_subsample` folder.) If you did not generate a larger training set earlier, you can use the small training set included in this git repo. You may need to regenerate the CNTK map file if image paths have been changed.\n",
    "\n",
    "### (Optional) Access the VM remotely via Jupyter Notebook\n",
    "\n",
    "Follow these steps if you wish to be able to access the notebook server remotely:\n",
    "1. In the [Azure Portal](https://portal.azure.com), navigate to the deployed VM's pane and determine its IP address.\n",
    "1. In the [Azure Portal](https://portal.azure.com), navigate to the deployed VM's Network Security Group's pane and add inbound/outbound rules permitting traffic on port 9999.\n",
    "1. While connected to the VM via remote desktop, launch a command prompt (Windows key + R) and type the following commands:\n",
    "\n",
    "   ```\n",
    "   cd C:\\dsvm\\tools\\setup\n",
    "   JupyterSetPasswordAndStart.cmd\n",
    "   ```\n",
    "\n",
    "   Follow the prompts to set your remote access password.\n",
    "   \n",
    "1. Connect to your VM remotely via Jupyter Notebooks using the IP address you determined earlier and port 9999, e.g. `https://[__.__.__.__]:9999`. The default directory on login will be `C:\\dsvm\\notebooks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tensorflow\"></a>\n",
    "## Tensorflow\n",
    "\n",
    "<a name=\"tfscript\"></a>\n",
    "### Training script\n",
    "\n",
    "We made use of the [`tf-slim` API](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) for Tensorflow, which provides pre-trained ResNet models and helpful scripts for retraining and scoring. During training set preparation, we converted raw PNG images to the [TFRecords](https://www.tensorflow.org/how_tos/reading_data/#file_formats) files that those scripts expect as input. (Our evaluation set images will be scored on Spark without conversion to TFRecord format.)\n",
    "\n",
    "Our training script is a modified version of `train_image_classifier.py` from the [Tensorflow models repo's slim subdirectory](https://github.com/tensorflow/models/tree/master/slim). Changes have also been made to some of that script's dependencies. We recommend that you clone this repo and transfer the `tf` subfolder, including dependencies, to a suitable location, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repo_dir = 'D:\\\\tf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tfmodel\"></a>\n",
    "### Model\n",
    "\n",
    "We will retrain the logits of a 152-layer ResNet pretrained on ImageNet. This model is highlighted in the [Tensorflow models repo's slim subdirectory](https://github.com/tensorflow/models/tree/master/slim). The pretrained model can be obtained and unpacked with the code snippet below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "urllib.request.urlretrieve('http://download.tensorflow.org/models/resnet_v1_152_2016_08_28.tar.gz',\n",
    "                           os.path.join(repo_dir, 'resnet_v1_152_2016_08_28.tar.gz'))\n",
    "with tarfile.open(os.path.join(repo_dir, 'resnet_v1_152_2016_08_28.tar.gz'), 'r:gz') as f:\n",
    "    f.extractall(path=repo_dir)\n",
    "os.remove(os.path.join(repo_dir, 'resnet_v1_152_2016_08_28.tar.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tfrun\"></a>\n",
    "### Running the training script\n",
    "\n",
    "We recommend that you run the training script from an Anaconda prompt. The code cell below will help you generate the appropriate command based on your file locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# repo_dir was defined above\n",
    "\n",
    "# path where retrained model and logs will be saved during training\n",
    "train_dir = os.path.join(repo_dir, 'models')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "    \n",
    "# location of the unpacked pretrained model\n",
    "checkpoint_path = os.path.join(repo_dir, 'resnet_v1_152.ckpt')\n",
    "\n",
    "# Location of the TFRecords and other files generated during image set preparation\n",
    "image_dir = 'D:\\\\combined\\\\train_subsample'\n",
    "\n",
    "command = '''activate py35\n",
    "python {0} --train_dir={1} --dataset_name=aerial --dataset_split_name=train --dataset_dir={2} --checkpoint_path={3}\n",
    "'''.format(os.path.join(repo_dir, 'retrain.py'),\n",
    "           train_dir,\n",
    "           dataset_dir,\n",
    "           checkpoint_path)\n",
    "\n",
    "print(command)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
