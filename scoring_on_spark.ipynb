{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring images on Spark\n",
    "\n",
    "This notebook illustrates how trained Cognitive Toolkit (CNTK) and TensorFlow models can be applied to large image collections using PySpark. For more detail on image set creation and model training, please see the rest of the [Embarrassingly Parallel Image Classification](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification) repository.\n",
    "\n",
    "## Outline\n",
    "- [Setting up a Microsoft HDInsight Spark cluster and Azure Data Lake Store](#setup)\n",
    "   - [Provisioning the resources](#provision)\n",
    "   - [Transferring the image set](#transfer)\n",
    "   - [Installing Cognitive Toolkit and Tensorflow](#install)\n",
    "- [Image scoring with PySpark](#pyspark)\n",
    "   - [Cognitive Toolkit](#cntk)\n",
    "   - [TensorFlow](#tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## Setting up a Microsoft HDInsight Spark cluster and associated Azure Data Lake Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"provision\"></a>\n",
    "### Provisioning the resources\n",
    "\n",
    "#### Azure Data Lake Store\n",
    "\n",
    "#### Azure HDInsight Spark Cluster\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "   <img src=\"./img/spark_adls_provisioning/new_resource_button.gif\" width=\"100 px\"/>\n",
    "1. In the search field that appears, enter \"HDInsight\" and press Enter.\n",
    "   <img src=\"./img/spark_adls_provisioning/resource_search_box.gif\" width=\"200 px\"/>\n",
    "\n",
    "1. In the search results, click on the \"HDInsight\" option published by Microsoft.\n",
    "   <img src=\"./img/spark_adls_provisioning/resource_search_result.gif\" width=\"400 px\"/>\n",
    "\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the HDInsight resource type.\n",
    "   <img src=\"./img/spark_adls_provisioning/create.gif\" width=\"100 px\"/>\n",
    "1. In the \"Basics\" section of the \"New HDInsight cluster\" pane:\n",
    "    1. Choose a unique cluster name and the appropriate subscription.\n",
    "    1. Click on \"Cluster configuration\" to load a pane of settings.\n",
    "       1. Set the cluster type to \"Spark\".\n",
    "       1. Set the version to \"Spark 2.0.2 (HDI 3.5)\".\n",
    "       <img src=\"./img/spark_adls_provisioning/cluster_type_settings.gif\" width=\"400 px\"/>\n",
    "       1. Click the \"Select\" button at the bottom of the pane.\n",
    "    1. Choose a password for the `admin` account. You will use this account to log into Jupyter Notebook later in the walkthrough.\n",
    "    1. Select or create an appropriate resource group.\n",
    "    1. Click the \"Next\" button at the bottom of the pane.\n",
    "1. In the \"Storage\" section of the \"New HDInsight cluster\" pane:\n",
    "   1. Ensure that \"Data Lake Store\" is selected for the \"Primary storage type\".\n",
    "   1. Click on \"Select Data Lake Storage Account\" to load a pane of settings.\n",
    "       1. Under \"Select a storage account\", select your ADLS.\n",
    "       1. Click on \"Configure Data Lake Access\" to load a pane of settings.\n",
    "           1. Create a new service principal.\n",
    "           1. Click on \"Access\" to load a pane of settings.\n",
    "               1. Under \"Select File Permissions\", click the box to the left of your ADLS name. (The box may be obscured until mouseover.). Click \"Select\".\n",
    "               1. Under \"Assign Selected Permissions\", click \"Run\".\n",
    "               1. When the run completes, click \"Done\".\n",
    "       1. Click the \"Next\" button at the bottom of the pane.\n",
    "1. In the \"Summary\" section of the \"New HDInsight cluster\" pane:\n",
    "   1. If desired, you can edit the cluster size settings to choose node counts/sizes based on your budget and time constraints. This tutorial can be completed using a cluster with **4** worker nodes and a node size of **D12 v2** (for both worker and head nodes). For more information, please see the [cluster](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters) and [VM](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-sizes#dv2-series) size guides.\n",
    "1. Click the \"Create\" button at the bottom of the pane.\n",
    "\n",
    "Cluster deployment may take approximately twenty minutes. (Since Azure Data Lake Store deployment will finish much sooner, we recommend transferring your image set to the ADLS while you wait; see the next section.) Cluster deployment status can be checked as follows:\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. During deployment, a blue bar will appear across the top of the overview pane with the title \"Applying changes\". When this bar disappears, deployment is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"transfer\"></a>\n",
    "### Transferring the image set\n",
    "\n",
    "Our evaluation image set was creating on a Data Science Virtual Machine. To transfer these images to our Azure Data Lake Store, we first copied the images to Azure Blob Storage using [AzCopy](https://docs.microsoft.com/en-gb/azure/storage/storage-use-azcopy), then to the Azure Data Lake Store with [AdlCopy](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob). After following the instructions linked above to download and install AzCopy/AdlCopy, we transferred the files with the following shell commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AzCopy /Source:E:\\combined\\test /Dest:https://mawahstorage.blob.core.windows.net/testing /DestKey:o62OKYWfsL/sNki1udZPWUZkOY5y6tL7cLRlgDTMciO9ZavfwmKqa8vNTNwrJXqkjeqHl9wJULwowfQFkj4/JA== /S\n",
      "AdlCopy /source https://mawahstorage.blob.core.windows.net/testing/ /dest swebhdfs://mawahtensorflow.azuredatalakestore.net/testing/ /sourcekey o62OKYWfsL/sNki1udZPWUZkOY5y6tL7cLRlgDTMciO9ZavfwmKqa8vNTNwrJXqkjeqHl9wJULwowfQFkj4/JA==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "local_image_dir = 'E:\\\\combined\\\\test'\n",
    "blob_account_name = 'mawahstorage'\n",
    "blob_account_key = 'o62OKYWfsL/sNki1udZPWUZkOY5y6tL7cLRlgDTMciO9ZavfwmKqa8vNTNwrJXqkjeqHl9wJULwowfQFkj4/JA=='\n",
    "blob_account_container = 'testing'\n",
    "adl_account_name = 'mawahtensorflow'\n",
    "adl_account_folder = 'testing'\n",
    "\n",
    "commands = '''\n",
    "AzCopy /Source:{0} /Dest:https://{1}.blob.core.windows.net/{2} /DestKey:{3} /S\n",
    "AdlCopy /source https://{1}.blob.core.windows.net/{2}/ /dest swebhdfs://{4}.azuredatalakestore.net/{5}/ /sourcekey {3}\n",
    "'''.format(local_image_dir, blob_account_name, blob_account_container,\n",
    "           blob_account_key, adl_account_name, adl_account_folder)\n",
    "\n",
    "print(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"install\"></a>\n",
    "### Installing Cognitive Toolkit and Tensorflow\n",
    "\n",
    "#### Obtaining and (optionally) modifying the script action\n",
    "\n",
    "We will install Cognitive Toolkit and Tensorflow on all head and worker nodes via Script Action. We have included a sample script action in the `scoring` subdirectory of [the Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification), reproduced below for your convenience:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#\n",
    "# This install script generously shared by Miruna Oprescu\n",
    "# (then lightly modified by Mary Wahl), Microsoft Corporation, 2017\n",
    "\n",
    "cntk_home=\"/usr/hdp/current\"\n",
    "cd $cntk_home\n",
    "curl \"BinaryDrop/CNTK-2-0-beta10-0-Linux-64bit-CPU-Only.tar.gz\" | tar xzf -\n",
    "cd ./cntk/Scripts/install/linux \n",
    "sed -i \"s#\"ANACONDA_PREFIX=\\\"\\$HOME/anaconda3\\\"\"#\"ANACONDA_PREFIX=\\\"\\/usr/bin/anaconda\\\"\"#g\" install-cntk.sh\n",
    "sed -i \"s#\"\\$HOME/anaconda3\"#\"\\$ANACONDA_PREFIX\"#g\" install-cntk.sh\n",
    "./install-cntk.sh --py-version 35\n",
    "\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install pillow\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install tensorflow\n",
    "\n",
    "sudo mkdir /tmp/resnet\n",
    "sudo chmod -R 777 /tmp/resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above installed CNTK 2.0 beta release 10. As of this writing, other CNTK releases can be substituted as follows:\n",
    "1. Navigate to the [CNTK Releases](https://github.com/Microsoft/CNTK/releases) page\n",
    "1. Click on the appropriate release's link for a Linux, CPU Only release.\n",
    "1. After reading and agreeing to the mentioned licenses, copy the URL linked to the \"I accept\" button (e.g. from the page source) and paste over the URL in the `curl` command above.\n",
    "\n",
    "#### Running the script action\n",
    "\n",
    "After HDInsight cluster deployment finishes, run the script action to install CNTK as follows:\n",
    "1. Obtain the URI for the script action.\n",
    "   - If using the unmodified version in this git repo, ensure that your URI points to the \"raw\" file (not a webpage-embedded file).\n",
    "   - If you have modified the script action, upload it to the website or Azure Blob Storage account of your choice and note its URI.\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. In the search field at upper left, type in \"Script actions\". Click the \"Script actions\" option in the results list.\n",
    "1. Click the \"+ Submit new\" button along the top of the Script Actions pane. A new pane of options will appear.\n",
    "   1. Under name, type \"install\" (without the quotes).\n",
    "   1. Under \"Bash script URI\", type in the URI.\n",
    "   1. Ensure that \"Head\" and \"Worker\" boxes are checked.\n",
    "   1. Click the \"Create\" button along the bottom of the pane.\n",
    "   \n",
    "Expect the script action to take roughly fifteen minutes to run.\n",
    "   \n",
    "#### Updating the Python 3 path\n",
    "\n",
    "The script action above installed Cognitive Toolkit and Tensorflow under a new Python environment, `cntk-py35`. Follow the steps below to direct PySpark to use this new environment:\n",
    "\n",
    "1. Navigate back to the HDInsight cluster's overview pane by clicking \"Overview\" near the upper left of the pane.\n",
    "1. Under \"Quick links\" in the main window, click the \"Cluster dashboards\" button. A new pane of dashboard options will appear.\n",
    "1. Click \"HDInsight cluster dashboard\". A new window will load.\n",
    "1. In the menu at left, click \"Spark2\".\n",
    "1. In the main window, click on the \"Configs\" tab.\n",
    "1. Scroll down to the \"Custom spark2-defaults\" option and expand its dropdown by clicking on the label (or triange beside it).\n",
    "1. Find the `spark.yarn.appMasterEnv.PYSPARK3_PYTHON` entry in the dropdown list. Change its path to the following:\n",
    "\n",
    "    `/usr/bin/anaconda/envs/cntk-py35/bin/python`<br/><br/>\n",
    "    \n",
    "1. Click on the green \"Save\" button that appears at upper right.\n",
    "1. When prompted, click the orange \"Restart\" button and select \"Restart all affected\".\n",
    "1. When the restart concludes, close the window. This will return you to a pane of dashboard options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"pyspark\"></a>\n",
    "## Image scoring with PySpark\n",
    "\n",
    "### Define common variables, including image RDD\n",
    "\n",
    "The following variables will be referenced by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adls_name = 'mawahtensorflow'\n",
    "adls_folder = 'testing'\n",
    "n_workers = 4\n",
    "local_tmp_dir = '/tmp/resnet'\n",
    "\n",
    "dataset_dir = 'adl://{}.azuredatalakestore.net/{}'.format(adls_name, adls_folder)\n",
    "image_rdd = sc.binaryFiles('{}/*/*.png'.format(dataset_dir), minPartitions=n_workers).coalesce(n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cntk\"></a>\n",
    "### Cognitive Toolkit (CNTK)\n",
    "\n",
    "#### Download the trained CNTK model\n",
    "\n",
    "Use the code segment below to download the trained CNTK ResNet and ensure the file will be accessible to workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cntk_model_uri = 'https://mawahstorage.blob.core.windows.net/examples/cntkonspark/resnet20_159.dnn'\n",
    "\n",
    "with open('{}/model.dnn'.format(local_tmp_dir), 'wb') as f:\n",
    "    f.write(urlopen(cntk_model_uri).read())\n",
    "sc.addFile('{}/model.dnn'.format(local_tmp_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an RDD of image data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tf\"></a>\n",
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the trained Tensorflow model\n",
    "\n",
    "TODO: link to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_model_uri = 'https://mawahstorage.blob.core.windows.net/examples/cntkonspark/resnet20_159.dnn'\n",
    "\n",
    "with open('{}/model.dnn'.format(local_tmp_dir), 'wb') as f:\n",
    "    f.write(urlopen(cntk_model_uri).read())\n",
    "sc.addFile('{}/model.dnn'.format(local_tmp_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import functools\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "sc.addPyFile('/tmp/resnet/tf/resnet_utils.py')\n",
    "sc.addPyFile('/tmp/resnet/tf/resnet_v1.py')\n",
    "import resnet_v1  # which has been modified based on an identified git issue\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Head node helper functions #\n",
    "##############################\n",
    "\n",
    "def read_label_file(dataset_dir, filename='labels.txt'):\n",
    "    labels_file = sc.wholeTextFiles('{}/{}'.format(dataset_dir, filename)).take(1)[0][1]\n",
    "    lines = labels_file.split('\\n')\n",
    "    lines = filter(None, lines)\n",
    "    labels_to_class_names = {}\n",
    "    for line in lines:\n",
    "        index = line.index(':')\n",
    "        labels_to_class_names[int(line[:index])] = line[index+1:]\n",
    "    return(labels_to_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Worker node helper functions #\n",
    "################################\n",
    "\n",
    "def get_network_fn(name, num_classes, weight_decay=0.0, is_training=False):\n",
    "    arg_scope = resnet_v1.resnet_arg_scope(weight_decay=weight_decay)\n",
    "    func = resnet_v1.resnet_v1_152\n",
    "    @functools.wraps(func)\n",
    "    def network_fn(images):\n",
    "        with slim.arg_scope(arg_scope):\n",
    "            return func(images, num_classes, is_training=is_training)\n",
    "    if hasattr(func, 'default_image_size'):\n",
    "        network_fn.default_image_size = func.default_image_size\n",
    "    return(network_fn)\n",
    "\n",
    "def mean_image_subtraction(image, means):\n",
    "    num_channels = image.get_shape().as_list()[-1]\n",
    "    channels = tf.split(2, num_channels, image)\n",
    "    for i in range(num_channels):\n",
    "        channels[i] -= means[i]\n",
    "    return(tf.concat(2, channels))\n",
    "\n",
    "def get_preprocessing():\n",
    "    def preprocessing_fn(image, output_height=224, output_width=224):\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        resized_image = tf.image.resize_bilinear(image, [output_height, output_width], align_corners=False)\n",
    "        resized_image = tf.squeeze(resized_image)\n",
    "        resized_image.set_shape([output_height, output_width, 3])\n",
    "        image = tf.to_float(resized_image)\n",
    "        return(mean_image_subtraction(image, [123.68, 116.78, 103.94]))\n",
    "    return(preprocessing_fn)\n",
    "\n",
    "def batch_label(files):    \n",
    "    labels_to_class_names = labels_to_class_names_bc.value\n",
    "    model_dir = model_dir_bc.value\n",
    "    \n",
    "    class_names = sorted(labels_to_class_names.values())\n",
    "    class_names_to_ids = dict(zip(class_names, list(range(len(class_names)))))\n",
    "    class_count = len(class_names)\n",
    "    results = []\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network_fn = get_network_fn('resnet_v1_152', num_classes=class_count, is_training=False)\n",
    "        image_preprocessing_fn = get_preprocessing()\n",
    "\n",
    "        current_image = tf.placeholder(tf.uint8, shape=(100, 100, 3))\n",
    "        preprocessed_image = image_preprocessing_fn(current_image, 224, 224)\n",
    "        image  = tf.expand_dims(preprocessed_image, 0)\n",
    "        logits, _ = network_fn(image)\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            my_saver = tf.train.Saver()\n",
    "            my_saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
    "\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            try:\n",
    "                for file in files:\n",
    "                    imported_image_np = np.asarray(Image.open(BytesIO(file[1])), dtype=np.uint8)\n",
    "                    result = sess.run(predictions, feed_dict={current_image: imported_image_np})\n",
    "                    class_name = file[0].split('/')[-2] # Extract class name from filename\n",
    "                    results.append((result[0], class_names_to_ids[class_name]))\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the full list of images and label/class info\n",
    "labels_to_class_names = read_label_file(dataset_dir)\n",
    "class_names = sorted(labels_to_class_names.values())\n",
    "class_names_to_ids = dict(zip(class_names, list(range(len(class_names)))))\n",
    "\n",
    "# Broadcast some information to workers\n",
    "local_tmp_dir_bc = sc.broadcast(local_tmp_dir)\n",
    "labels_to_class_names_bc = sc.broadcast(labels_to_class_names)\n",
    "\n",
    "# Split up the image list into n_workers partitions\n",
    "labelled_images = image_rdd.mapPartitions(batch_label)\n",
    "results = labelled_images.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
