{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Scoring images on Spark\n",
    "\n",
    "This notebook illustrates how trained Cognitive Toolkit (CNTK) and TensorFlow models can be applied to large image collections using PySpark. For more detail on image set creation and model training, please see the rest of the [Embarrassingly Parallel Image Classification](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification) repository.\n",
    "\n",
    "## Outline\n",
    "- [Set up a Microsoft HDInsight Spark cluster and Azure Data Lake Store](#setup)\n",
    "   - [Provision the resources](#provision)\n",
    "   - [Transfer the image set and models](#transfer)\n",
    "   - [Install Cognitive Toolkit and Tensorflow](#install)\n",
    "- [Image scoring with PySpark](#pyspark)\n",
    "   - [Cognitive Toolkit](#cntk)\n",
    "   - [TensorFlow](#tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"setup\"></a>\n",
    "## Setting up a Microsoft HDInsight Spark cluster and associated Azure Data Lake Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"provision\"></a>\n",
    "### Provision the resources\n",
    "\n",
    "#### Azure Data Lake Store\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "1. In the search field that appears, enter \"Data Lake Store\" and press Enter.\n",
    "1. In the search results, click on the \"Data Lake Store\" option published by Microsoft.\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the Data Lake Store resource type.\n",
    "1. Choose a unique name, subscription, resource group, and location for your Data Lake Store. Note the location: you will need to use the same location when deploying the Spark cluster.\n",
    "   - Some Azure subscriptions limit the number of HDInsight cores that can be used by location. Ensure that you choose a location where you will be able to generate an HDInsight cluster with 48 cores.\n",
    "1. Select the appropriate pricing plan for your needs. (We recommend \"Pay-as-you-go\"; the tutorial will use <1 TB of data.)\n",
    "1. Click the \"Create\" button at the bottom of the pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure HDInsight Spark Cluster\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "1. In the search field that appears, enter \"HDInsight\" and press Enter.\n",
    "1. In the search results, click on the \"HDInsight\" option published by Microsoft.\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the HDInsight resource type.\n",
    "1. In the \"Basics\" section of the \"New HDInsight cluster\" pane:\n",
    "    1. Choose a unique cluster name and the appropriate subscription.\n",
    "    1. Click on \"Cluster configuration\" to load a pane of settings.\n",
    "       1. Set the cluster type to \"Spark\".\n",
    "       1. Set the version to \"Spark 2.0.2 (HDI 3.5)\".\n",
    "       1. Click the \"Select\" button at the bottom of the pane.\n",
    "    1. Choose a password for the `admin` account. You will use this account to log into Jupyter Notebook later in the walkthrough.\n",
    "    1. Select the resource group and location where your Data Lake Store is located.\n",
    "    1. Click the \"Next\" button at the bottom of the pane.\n",
    "1. In the \"Storage\" section of the \"New HDInsight cluster\" pane:\n",
    "   1. Ensure that \"Data Lake Store\" is selected for the \"Primary storage type\".\n",
    "   1. Click on \"Select Data Lake Storage Account\" to load a pane of settings.\n",
    "       1. Under \"Select a storage account\", select your Azure Data Lake store.\n",
    "       1. Change the \"root path\" to \"/clusters\".\n",
    "          - The default option, \"/clusters/<cluster name>\", will not work unless you have previously created a \"/clusters\" folder in your Azure Data Lake Store.\n",
    "       1. Click on \"Configure Data Lake Access\" to load a pane of settings.\n",
    "           1. Create a new service principal with the name and password of your choice. Save the generated certificate file.\n",
    "           1. Click on \"Access\" to load a pane of settings.\n",
    "               1. Under \"Select File Permissions\", click the box to the left of your ADLS name. (The box may be obscured until mouseover.). Click \"Select\".\n",
    "               1. Under \"Assign Selected Permissions\", click \"Run\".\n",
    "               1. When the run completes, click \"Done\".\n",
    "       1. Click the \"Next\" button at the bottom of the pane.\n",
    "1. In the \"Summary\" section of the \"New HDInsight cluster\" pane:\n",
    "   1. If desired, you can edit the cluster size settings to choose node counts/sizes based on your budget and time constraints. We recommend completing this tutorial using a cluster with **10** worker nodes and a node size of **D12 v2** (for both worker and head nodes). For more information, please see the [cluster](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters) and [VM](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-sizes#dv2-series) size guides.\n",
    "1. Click the \"Create\" button at the bottom of the pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking cluster deployment status\n",
    "\n",
    "Cluster deployment may take approximately twenty minutes. (We recommend that you continue with the tutorial, creating all other Azure resources and transferring your image set to the Azure Data Lake Store, while you wait for the cluster to deploy.) Cluster deployment status can be checked as follows:\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. During deployment, a blue bar will appear across the top of the overview pane with the title \"Applying changes\". When this bar disappears, deployment is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Azure Blob Storage account\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "1. In the search field that appears, enter \"Storage account\" and press Enter.\n",
    "1. In the search results, click on the \"Storage account\" option published by Microsoft.\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the Storage account resource type.\n",
    "1. Enter a name for the blob storage account.\n",
    "1. Select the same resource group and location as the Azure Data Lake Store you created earlier.\n",
    "1. Click the \"Create\" button to deploy the new storage account.\n",
    "1. When the Storage account's deployment finishes, navigate to its overview pane using the search functionality described above.\n",
    "1. In the left-hand menu, under Settings, click on Access Keys. Note the primary key, which we will use for transferring images from the GPU VM to the Azure Data Lake Store.\n",
    "1. Return to the Storage account's Overview pane and click on \"Blobs\".\n",
    "1. Click \"+ Container\" near the top of the Blob service pane.\n",
    "1. Enter the name \"balancedtest\" and click \"Create\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure Data Factory\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "1. In the search field that appears, enter \"Data Factory\" and press Enter.\n",
    "1. In the search results, click on the \"Data Factory\" option published by Microsoft.\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the Data Factory resource type.\n",
    "1. Choose a unique name, subscription, resource group, and location for your Data Factory.\n",
    "   - Do not worry if you cannot match the location of your Azure Data Lake Store/Storage account. This will not affect file transfer rates.\n",
    "1. Click the \"Create\" button at the bottom of the pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"transfer\"></a>\n",
    "### Transfer the image set\n",
    "\n",
    "#### Transfer from the VM to blob storage\n",
    "Once the [balanced validation image set](https://mawahstorage.blob.core.windows.net/aerialimageclassification/imagesets/balanced_validation_set.zip) has been downloaded and decompressed, the images can be transferred to the Data Lake Store via Azure Blob Storage. In the first stage, files are copied to Azure Blob Storage using [AzCopy](https://docs.microsoft.com/en-gb/azure/storage/storage-use-azcopy). After downloading and installing AzCopy, you can generate the necessary commands for the file transfer using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Be sure to fill in your credentials before running!\n",
    "local_image_dir = 'D:\\\\balanced_validation_set\\'\n",
    "blob_account_name = ''\n",
    "blob_account_key = ''\n",
    "blob_account_container = 'balancedtest'\n",
    "\n",
    "command = '''\n",
    "AzCopy /Source:{0} /Dest:https://{1}.blob.core.windows.net/{2} /DestKey:{3} /S\n",
    "'''.format(local_image_dir, blob_account_name, blob_account_container,\n",
    "           blob_account_key)\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "This command should be run from a CLI interface and will take several minutes to complete. After running this command, you should find that your validation set images have been transferred to the `balancedtest` container in your Blob storage account. You can visually confirm this by navigating to the Storage account's overview page, clicking on Blobs, then clicking on the `balancedtest` container's name. The directory structure displayed can be navigated in the usual way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer files from blob storage to Azure Data Lake Store using Azure Data Factory\n",
    "\n",
    "1. Navigate to your data factory's overview pane in Azure Portal and click \"Copy data (PREVIEW)\" to launch a guided walkthrough of transfer pipeline setup.\n",
    "1. Set the task cadence to \"Run once now.\" Leaving all other settings at their default values, click \"Next\".\n",
    "1. For the source connection, select \"Azure Blob Storage\" and click \"Next\".\n",
    "1. Choose your Azure subscription's name, then the name of your Blob storage account. Click \"Next\".\n",
    "1. Choose \"balancedtest\" as your input folder by clicking on its name. Click the \"Choose\" button.\n",
    "1. Check the \"Copy files recursively\" and \"Binary copy\" checkboxes, then click \"Next\".\n",
    "1. For the destination connection, select \"Azure Data Lake Store\" and click \"Next\".\n",
    "1. Choose your Azure subscription's name, then the name of your Azure Data Lake Store. Set the authentication type to \"OAuth\". Click \"Next\".\n",
    "1. Type \"/balancedtest\" in the Folder path field. Click \"Next\".\n",
    "1. Click \"Next\" without changing the advanced settings.\n",
    "1. On the Summary page, click \"Authorize\" next to \"Linked service Destination...\" and provide your credentials. Click \"Next\".\n",
    "1. After the pipeline is deployed, data transfer will begin. You can monitor progress by navigating to your Azure Data Lake Store's overview page and clicking \"Data Explorer\" along the top bar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The notebook code below has been written to install the [CNTK]() and [TF]() DNNs we generated. If you prefer to use your own model files, we recommend that you upload them to your Blob Storage account and download them to your Spark cluster. The sample files and code below can be used aas a template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"install\"></a>\n",
    "### Install Cognitive Toolkit and Tensorflow\n",
    "\n",
    "#### Obtain the script action\n",
    "\n",
    "We will install Cognitive Toolkit and Tensorflow on all head and worker nodes via Script Action. We have included a sample script action in the `scoring` subdirectory of [the Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification), reproduced below for your convenience:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#!/bin/bash\n",
    "#\n",
    "# This install script generously shared by Miruna Oprescu\n",
    "# (then lightly modified by Mary Wahl), Microsoft Corporation, 2017\n",
    "\n",
    "cntk_home=\"/usr/hdp/current\"\n",
    "cd $cntk_home\n",
    "curl \"https://cntk.ai/BinaryDrop/CNTK-2-0rc1-Linux-64bit-CPU-Only.tar.gz\" | tar xzf -\n",
    "cd ./cntk/Scripts/install/linux \n",
    "sed -i \"s#\"ANACONDA_PREFIX=\\\"\\$HOME/anaconda3\\\"\"#\"ANACONDA_PREFIX=\\\"\\/usr/bin/anaconda\\\"\"#g\" install-cntk.sh\n",
    "sed -i \"s#\"\\$HOME/anaconda3\"#\"\\$ANACONDA_PREFIX\"#g\" install-cntk.sh\n",
    "./install-cntk.sh --py-version 35\n",
    "\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install pillow\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install tensorflow==0.12.1\n",
    "\n",
    "sudo mkdir /tmp/models\n",
    "cd /tmp/models\n",
    "wget https://mawahstorage.blob.core.windows.net/aerialimageclassification/models/tf.zip -P /tmp/models\n",
    "unzip /tmp/models/tf.zip\n",
    "wget https://mawahstorage.blob.core.windows.net/aerialimageclassification/models/cntkv2rc1_50.dnn -P /tmp/models\n",
    "sudo chmod -R 777 /tmp/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script action above will copy our pretrained models (the files `cntkv2rc1_50.dnn` and `tf.zip`) to your HDInsight cluster. If you prefer to use your own models, you can replace the URIs above with the URIs of models that you upload to blob storage. (You can upload a file to blob storage by navigating to the storage account's overview pane, clicking on \"Blobs\", clicking on the desired destination container name, and clicking \"Upload\".)\n",
    "\n",
    "The code above installed CNTK 2.0 RC1. As of this writing, other CNTK releases can be substituted as follows:\n",
    "1. Navigate to the [CNTK Releases](https://github.com/Microsoft/CNTK/releases) page\n",
    "1. Click on the appropriate release's link for a Linux, CPU Only release.\n",
    "1. After reading and agreeing to the mentioned licenses, copy the URL linked to the \"I accept\" button (e.g. from the page source) and paste over the URL in the `curl` command above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Running the script action\n",
    "\n",
    "After HDInsight cluster deployment finishes, run the script action to install CNTK as follows:\n",
    "1. Obtain the URI for the script action.\n",
    "   - If using the unmodified version in the `scoring` subdirectory of this git repo, ensure that your URI points to the \"raw\" file (not a webpage-embedded file), e.g.:\n",
    "   [https://github.com/Azure/Embarrassingly-Parallel-Image-Classification/raw/master/scoring/script_action.sh](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification/raw/master/scoring/script_action.sh)\n",
    "   - If you have modified the script action, upload it to the website or Azure Blob Storage account of your choice and note its URI.\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. In the search field at upper left, type in \"Script actions\". Click the \"Script actions\" option in the results list.\n",
    "1. Click the \"+ Submit new\" button along the top of the Script Actions pane. A new pane of options will appear.\n",
    "   1. Under name, type \"install\" (without the quotes).\n",
    "   1. Under \"Bash script URI\", type in the URI.\n",
    "   1. Ensure that \"Head\" and \"Worker\" boxes are checked.\n",
    "   1. Click the \"Create\" button along the bottom of the pane.\n",
    "   \n",
    "Expect the script action to take roughly fifteen minutes to run. When the script action is complete, the blue bar at the top of the screen will disappear and a green icon will appear next to the submitted script action's name. Do not proceed until the script action has finished.\n",
    "   \n",
    "#### Updating the Python 3 path\n",
    "\n",
    "The script action above installed Cognitive Toolkit and Tensorflow under a new Python environment, `cntk-py35`. Follow the steps below to direct PySpark to use this new environment:\n",
    "\n",
    "1. Navigate back to the HDInsight cluster's overview pane by clicking \"Overview\" near the upper left of the pane.\n",
    "1. Under \"Quick links\" in the main window, click the \"Cluster dashboards\" button. A new pane of dashboard options will appear.\n",
    "1. Click \"HDInsight cluster dashboard\". A new window will load. You may be asked for the username (default: admin) and password you selected during deployment.\n",
    "1. In the menu at left, click \"Spark2\".\n",
    "1. In the main window, click on the \"Configs\" tab.\n",
    "1. Scroll down to the \"Custom spark2-defaults\" option and expand its dropdown by clicking on the label (or triange beside it).\n",
    "1. Find the `spark.yarn.appMasterEnv.PYSPARK3_PYTHON` entry in the dropdown list. Change its path to the following:\n",
    "\n",
    "    `/usr/bin/anaconda/envs/cntk-py35/bin/python`<br/><br/>\n",
    "    \n",
    "1. Click on the green \"Save\" button that appears at upper right.\n",
    "1. When prompted, click the orange \"Restart\" button and select \"Restart all affected\".\n",
    "1. When the restart concludes, close the window. This will return you to a pane of dashboard options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Upload and start this notebook on HDInsight Spark\n",
    "\n",
    "1. On the Overview pane of your HDInsight Spark cluster, click on \"Cluster dashboards\" and select \"Jupyter Notebooks\".\n",
    "1. If prompted, log in with the username (default: admin) and password you selected during deployment.\n",
    "1. Use the \"Upload\" button to upload a copy of this notebook. You may be prompted to confirm the destination filename during the upload process: the default value will do.\n",
    "1. Once the notebook has been uploaded, double-check on the notebook's name to launch it.\n",
    "1. The PySpark3 kernel should be used to run the notebook. If necessary, change the kernel by clicking \"Kernel -> Change Kernel -> PySpark3\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"pyspark\"></a>\n",
    "## Image scoring with PySpark\n",
    "\n",
    "### Define functions/variables/RDDs used by both scoring pipelines\n",
    "\n",
    "Edit the variables below to define the name of your Azure Data Lake Store and the folder where the images have been stored. Execute the code cell to create an RDD of the images in the test set. Note that if this is the first code cell executed, there will be an additional delay as the Spark connection initiates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "def get_nlcd_id(my_filename):\n",
    "    ''' Extracts the true label  '''\n",
    "    folder, _ = os.path.split(my_filename)\n",
    "    return(int(os.path.basename(folder)))\n",
    "\n",
    "adls_name = ''\n",
    "adls_folder = 'balancedtest'\n",
    "\n",
    "n_workers = 10\n",
    "local_tmp_dir = '/tmp/models'\n",
    "\n",
    "dataset_dir = 'adl://{}.azuredatalakestore.net/{}'.format(adls_name, adls_folder)\n",
    "image_rdd = sc.binaryFiles('{}/*/*.png'.format(dataset_dir), minPartitions=n_workers).coalesce(n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"cntk\"></a>\n",
    "### Score and evaluate with a trained Cognitive Toolkit (CNTK) model\n",
    "\n",
    "#### Make the trained CNTK model available to all workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cntk import load_model\n",
    "\n",
    "cntk_model_filepath = '{}/cntkv2rc1_50.dnn'.format(local_tmp_dir)\n",
    "cntk_model_filepath_bc = sc.broadcast(cntk_model_filepath)\n",
    "sc.addFile(cntk_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define functions to be run by worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cntk_get_preprocessed_image(filename):\n",
    "    ''' Perform transposition and RGB -> BGR permutation '''\n",
    "    image_data = np.array(Image.open(filename), dtype=np.float32)\n",
    "    bgr_image = image_data[:, :, ::-1]\n",
    "    image_data = np.ascontiguousarray(np.transpose(bgr_image, (2,0,1)))\n",
    "    return(image_data)\n",
    "\n",
    "def cntk_run_worker(files):\n",
    "    ''' Scoring script run by each worker '''\n",
    "    cntk_model_filepath = cntk_model_filepath_bc.value\n",
    "    loaded_model = load_model(SparkFiles.get(cntk_model_filepath))\n",
    "    \n",
    "    # Iterate through the files. The first value in each tuple is the file name; the second is the image data\n",
    "    for file in files:\n",
    "        preprocessed_image = cntk_get_preprocessed_image(BytesIO(file[1]))\n",
    "        dnn_output = loaded_model.eval({loaded_model.arguments[0]: [preprocessed_image]})\n",
    "        true_label = get_nlcd_id(file[0])\n",
    "        yield (file[0], true_label, np.argmax(np.squeeze(dnn_output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Score all test set images with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored 11760 images\n",
      "0:04:35.190213"
     ]
    }
   ],
   "source": [
    "labeled_images = image_rdd.mapPartitions(cntk_run_worker)\n",
    "\n",
    "start = pd.datetime.now()\n",
    "cntk_results = labeled_images.collect()\n",
    "print('Scored {} images'.format(len(cntk_results)))\n",
    "stop = pd.datetime.now()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Evaluate the model's performance\n",
    "\n",
    "We first report the model's raw overall accuracy. We then calculate the overall accuracy when all undeveloped land types are grouped under the same label. (We will use the latter grouping in a subsequent notebook to simplify result interpretation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using all six categories, correctly predicted 9212 of 11760 images (78.33%)\n",
      "After regrouping land use categories, correctly predicted 10818 of 11760 images (91.99%)"
     ]
    }
   ],
   "source": [
    "def group_undeveloped_land_types(original_label):\n",
    "    if original_label in [3, 5]:  # developed and cultivated land types\n",
    "        return(original_label)\n",
    "    else:\n",
    "        return(6)  # new grouped label for all undeveloped land types\n",
    "\n",
    "cntk_df = pd.DataFrame(cntk_results, columns=['filename', 'true_label', 'predicted_label'])\n",
    "num_correct = sum(cntk_df['true_label'] == cntk_df['predicted_label'])\n",
    "num_total = len(cntk_results)\n",
    "print('When using all six categories, correctly predicted ' +\n",
    "      '{} of {} images ({:0.2f}%)'.format(num_correct,\n",
    "                                          num_total,\n",
    "                                          100 * num_correct / num_total))\n",
    "\n",
    "cntk_df['true_label_regrouped'] = cntk_df['true_label'].apply(group_undeveloped_land_types)\n",
    "cntk_df['predicted_label_regrouped'] = cntk_df['predicted_label'].apply(group_undeveloped_land_types)\n",
    "num_correct = sum(cntk_df['true_label_regrouped'] == cntk_df['predicted_label_regrouped'])\n",
    "print('After regrouping land use categories, correctly predicted ' +\n",
    "      '{} of {} images ({:0.2f}%)'.format(num_correct,\n",
    "                                          num_total,\n",
    "                                          100 * num_correct / num_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"tf\"></a>\n",
    "### Score and evaluate with a trained TensorFlow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Make the trained TensorFlow model available to all workers\n",
    "\n",
    "Loads a slightly modified version of the tf-slim ResNet definition from the [TensorFlow models git repository](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc.addPyFile(os.path.join(local_tmp_dir, 'resnet_utils.py'))\n",
    "sc.addPyFile(os.path.join(local_tmp_dir, 'resnet_v1.py'))\n",
    "model_dir_bc = sc.broadcast(local_tmp_dir)\n",
    "\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import resnet_v1\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define functions used by workers for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_network_fn(num_classes, weight_decay=0.0, is_training=False):\n",
    "    arg_scope = resnet_v1.resnet_arg_scope(weight_decay=weight_decay)\n",
    "    func = resnet_v1.resnet_v1_50\n",
    "    @functools.wraps(func)\n",
    "    def network_fn(images):\n",
    "        with slim.arg_scope(arg_scope):\n",
    "            return func(images, num_classes, is_training=is_training)\n",
    "    if hasattr(func, 'default_image_size'):\n",
    "        network_fn.default_image_size = func.default_image_size\n",
    "    return(network_fn)\n",
    "\n",
    "def mean_image_subtraction(image, means):\n",
    "    num_channels = image.get_shape().as_list()[-1]\n",
    "    channels = tf.split(2, num_channels, image)\n",
    "    for i in range(num_channels):\n",
    "        channels[i] -= means[i]\n",
    "    return(tf.concat(2, channels))\n",
    "\n",
    "def get_preprocessing():\n",
    "    def preprocessing_fn(image, output_height=224, output_width=224):\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        resized_image = tf.image.resize_bilinear(image, [output_height, output_width], align_corners=False)\n",
    "        resized_image = tf.squeeze(resized_image)\n",
    "        resized_image.set_shape([output_height, output_width, 3])\n",
    "        image = tf.to_float(resized_image)\n",
    "        return(mean_image_subtraction(image, [123.68, 116.78, 103.94]))\n",
    "    return(preprocessing_fn)\n",
    "\n",
    "def tf_run_worker(files):\n",
    "    model_dir = model_dir_bc.value\n",
    "    results = []\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network_fn = get_network_fn(num_classes=6, is_training=False)\n",
    "        image_preprocessing_fn = get_preprocessing()\n",
    "        \n",
    "        current_image = tf.placeholder(tf.uint8, shape=(224, 224, 3))\n",
    "        preprocessed_image = image_preprocessing_fn(current_image, 224, 224)\n",
    "        image  = tf.expand_dims(preprocessed_image, 0)\n",
    "        logits, _ = network_fn(image)\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            my_saver = tf.train.Saver()\n",
    "            my_saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
    "            \n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            try:\n",
    "                for file in files:\n",
    "                    imported_image_np = np.asarray(Image.open(BytesIO(file[1])), dtype=np.uint8)\n",
    "                    result = sess.run(predictions, feed_dict={current_image: imported_image_np})\n",
    "                    true_label = get_nlcd_id(file[0])\n",
    "                    results.append([file[0], true_label, result[0]])\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Score all images with trained TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored 11760 images\n",
      "0:05:24.885293"
     ]
    }
   ],
   "source": [
    "labeled_images_tf = image_rdd.mapPartitions(tf_run_worker)\n",
    "\n",
    "start = pd.datetime.now()\n",
    "results_tf = labeled_images_tf.collect()\n",
    "print('Scored {} images'.format(len(results_tf)))\n",
    "stop = pd.datetime.now()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Evaluate the model's performance\n",
    "\n",
    "We first report the model's raw overall accuracy. We also report the overall accuracy when all undeveloped land types are grouped under the same label. (We will use the latter grouping in a subsequent notebook to simplify result interpretation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When using all six categories, correctly predicted 9611 of 11760 images (81.73%)\n",
      "After regrouping land use categories, correctly predicted 10788 of 11760 images (91.73%)"
     ]
    }
   ],
   "source": [
    "def group_undeveloped_land_types(original_label):\n",
    "    if original_label in [3, 5]:  # developed and cultivated land types\n",
    "        return(original_label)\n",
    "    else:\n",
    "        return(6)\n",
    "\n",
    "tf_df = pd.DataFrame(results_tf, columns=['filename', 'true_label', 'predicted_label'])\n",
    "num_correct = sum(tf_df['true_label'] == tf_df['predicted_label'])\n",
    "num_total = len(results_tf)\n",
    "print('When using all six categories, correctly predicted {} of {} images ({:0.2f}%)'.format(num_correct,\n",
    "                                                                                             num_total,\n",
    "                                                                                             100 * num_correct / num_total))\n",
    "\n",
    "tf_df['true_label_regrouped'] = tf_df['true_label'].apply(group_undeveloped_land_types)\n",
    "tf_df['predicted_label_regrouped'] = tf_df['predicted_label'].apply(group_undeveloped_land_types)\n",
    "num_correct = sum(tf_df['true_label_regrouped'] == tf_df['predicted_label_regrouped'])\n",
    "print('After regrouping land use categories, correctly predicted {} of {} images ({:0.2f}%)'.format(num_correct,\n",
    "                                                                                                    num_total,\n",
    "                                                                                                    100 * num_correct / num_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"next\"></a>\n",
    "## Next Steps\n",
    "\n",
    "For an example of how the trained model can be applied to identify newly developed regions and explore county-level patterns in development, please see the next document in this repository: [Land Use Prediction in Middlesex County, MA](land_use_prediction.md)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
