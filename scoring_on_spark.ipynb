{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring images on Spark\n",
    "\n",
    "This notebook illustrates how trained Cognitive Toolkit (CNTK) and TensorFlow models can be applied to large image collections using PySpark. For more detail on image set creation and model training, please see the rest of the [Embarrassingly Parallel Image Classification](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification) repository.\n",
    "\n",
    "## Outline\n",
    "- [Setting up a Microsoft HDInsight Spark cluster and Azure Data Lake Store](#setup)\n",
    "   - [Provisioning the resources](#provision)\n",
    "   - [Transferring the image set](#transfer)\n",
    "   - [Installing Cognitive Toolkit and Tensorflow](#install)\n",
    "- [Image scoring with PySpark](#pyspark)\n",
    "   - [Cognitive Toolkit](#cntk)\n",
    "   - [TensorFlow](#tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## Setting up a Microsoft HDInsight Spark cluster and associated Azure Data Lake Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"provision\"></a>\n",
    "### Provisioning the resources\n",
    "\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "1. In the search field that appears, enter \"HDInsight\" and press Enter.\n",
    "1. In the search results, click on the \"HDInsight\" option published by Microsoft.\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the HDInsight resource type.\n",
    "1. In the \"New HDInsight cluster\" pane, choose a unique cluster name and the appropriate subscription.\n",
    "1. Click on \"Cluster configuration\" to load a pane of settings.\n",
    "   1. Set the cluster type to \"Spark\".\n",
    "   1. Set the version to \"Spark 2.0.1 (HDI 3.5)\".\n",
    "   1. Click the \"Select\" button at the bottom of the pane.\n",
    "1. Click on \"Credentials\" to load a pane of settings.\n",
    "   1. Choose a password for the `admin` account. You will use this account to log into Jupyter Notebook later in the walkthrough.\n",
    "   1. Choose a username and password for SSH access. We will not use this account in this walkthrough.\n",
    "   1. Click the \"Select\" button at the bottom of the pane.\n",
    "1. Click on \"Data source\" to load a pane of settings.\n",
    "   1. Ensure that \"Azure Storage\" is selected for the \"Primary storage type\".\n",
    "   1. Under \"Select a storage account\", click Create New.\n",
    "   1. Choose a name for the new storage account.\n",
    "   1. Under \"Default container\", enter \"hdinsight\" (without the quotes).\n",
    "   1. Click the \"Select\" button at the bottom of the pane.\n",
    "1. Click on \"Cluster size\" to load a pane of settings.\n",
    "   1. Choose a number of workers and node sizes according to your budget and time constraints. This tutorial can be completed using a cluster with **4** worker nodes and a node size of **D12 v2** (for both worker and head nodes). For more information, please see the [cluster](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters) and [VM](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-sizes#dv2-series) size guides.\n",
    "   1. Click the \"Select\" button at the bottom of the pane.\n",
    "1. Choose \"Create new\" under resource group, and enter a unique resource group name.\n",
    "1. Click the \"Create\" button at the bottom of the pane.\n",
    "\n",
    "Cluster deployment will take approximately twenty minutes. (Since Azure Data Lake Store deployment will finish much sooner, we recommend transferring your image set to the ADLS while you wait; see the next section.) Cluster deployment status can be checked as follows:\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. During deployment, a blue bar will appear across the top of the overview pane with the title \"Applying changes\". When this bar disappears, deployment is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"transfer\"></a>\n",
    "### Transferring the image set\n",
    "\n",
    "Our evaluation image set was creating on a Data Science Virtual Machine. To transfer these images to our Azure Data Lake Store, we first copied the images to Azure Blob Storage using [AzCopy](https://docs.microsoft.com/en-gb/azure/storage/storage-use-azcopy), then to the Azure Data Lake Store with [AdlCopy](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob). After following the instructions linked above to download and install AzCopy/AdlCopy, we transferred the files with the following shell commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AzCopy /Source:E:\\combined\\train /Dest:https://mawahstorage.blob.core.windows.net/training /DestKey:o62OKYWfsL/sNki1udZPWUZkOY5y6tL7cLRlgDTMciO9ZavfwmKqa8vNTNwrJXqkjeqHl9wJULwowfQFkj4/JA== /S\n",
      "AdlCopy /source https://mawahstorage.blob.core.windows.net/training/ /dest swebhdfs://mawahtensorflow.azuredatalakestore.net/training/ /sourcekey o62OKYWfsL/sNki1udZPWUZkOY5y6tL7cLRlgDTMciO9ZavfwmKqa8vNTNwrJXqkjeqHl9wJULwowfQFkj4/JA==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "local_image_dir = 'E:\\\\combined\\\\train'\n",
    "blob_account_name = 'mawahstorage'\n",
    "blob_account_key = 'o62OKYWfsL/sNki1udZPWUZkOY5y6tL7cLRlgDTMciO9ZavfwmKqa8vNTNwrJXqkjeqHl9wJULwowfQFkj4/JA=='\n",
    "blob_account_container = 'training'\n",
    "adl_account_name = 'mawahtensorflow'\n",
    "adl_account_folder = 'training'\n",
    "\n",
    "commands = '''\n",
    "AzCopy /Source:{0} /Dest:https://{1}.blob.core.windows.net/{2} /DestKey:{3} /S\n",
    "AdlCopy /source https://{1}.blob.core.windows.net/{2}/ /dest swebhdfs://{4}.azuredatalakestore.net/{5}/ /sourcekey {3}\n",
    "'''.format(local_image_dir, blob_account_name, blob_account_container,\n",
    "           blob_account_key, adl_account_name, adl_account_folder)\n",
    "\n",
    "print(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"install\"></a>\n",
    "### Installing Cognitive Toolkit and Tensorflow\n",
    "\n",
    "#### Obtaining and (optionally) modifying the script action\n",
    "\n",
    "We will install Cognitive Toolkit and Tensorflow on all head and worker nodes via Script Action. We have included a sample script action in the `scoring` subdirectory of [the Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification), reproduced below for your convenience:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#\n",
    "# This install script generously shared by Miruna Oprescu\n",
    "# (then lightly modified by Mary Wahl), Microsoft Corporation, 2017\n",
    "\n",
    "cntk_home=\"/usr/hdp/current\"\n",
    "cd $cntk_home\n",
    "curl \"BinaryDrop/CNTK-2-0-beta10-0-Linux-64bit-CPU-Only.tar.gz\" | tar xzf -\n",
    "cd ./cntk/Scripts/install/linux \n",
    "sed -i \"s#\"ANACONDA_PREFIX=\\\"\\$HOME/anaconda3\\\"\"#\"ANACONDA_PREFIX=\\\"\\/usr/bin/anaconda\\\"\"#g\" install-cntk.sh\n",
    "sed -i \"s#\"\\$HOME/anaconda3\"#\"\\$ANACONDA_PREFIX\"#g\" install-cntk.sh\n",
    "./install-cntk.sh --py-version 35\n",
    "\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install pillow\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install tensorflow\n",
    "\n",
    "sudo mkdir /tmp/resnet\n",
    "sudo chmod -R 777 /tmp/resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above installed CNTK 2.0 beta release 10. As of this writing, other CNTK releases can be substituted as follows:\n",
    "1. Navigate to the [CNTK Releases](https://github.com/Microsoft/CNTK/releases) page\n",
    "1. Click on the appropriate release's link for a Linux, CPU Only release.\n",
    "1. After reading and agreeing to the mentioned licenses, copy the URL linked to the \"I accept\" button (e.g. from the page source) and paste over the URL in the `curl` command above.\n",
    "\n",
    "#### Running the script action\n",
    "\n",
    "After HDInsight cluster deployment finishes, run the script action to install CNTK as follows:\n",
    "1. Obtain the URI for the script action.\n",
    "   - If using the unmodified version in this git repo, ensure that your URI points to the \"raw\" file (not a webpage-embedded file).\n",
    "   - If you have modified the script action, upload it to the website or Azure Blob Storage account of your choice and note its URI.\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. In the search field at upper left, type in \"Script actions\". Click the \"Script actions\" option in the results list.\n",
    "1. Click the \"+ Submit new\" button along the top of the Script Actions pane. A new pane of options will appear.\n",
    "   1. Under name, type \"install\" (without the quotes).\n",
    "   1. Under \"Bash script URI\", type in the URI.\n",
    "   1. Ensure that \"Head\" and \"Worker\" boxes are checked.\n",
    "   1. Click the \"Create\" button along the bottom of the pane.\n",
    "   \n",
    "Expect the script action to take roughly fifteen minutes to run.\n",
    "   \n",
    "#### Updating the Python 3 path\n",
    "\n",
    "The script action above installed Cognitive Toolkit and Tensorflow under a new Python environment, `cntk-py35`. Follow the steps below to direct PySpark to use this new environment:\n",
    "\n",
    "1. Navigate back to the HDInsight cluster's overview pane by clicking \"Overview\" near the upper left of the pane.\n",
    "1. Under \"Quick links\" in the main window, click the \"Cluster dashboards\" button. A new pane of dashboard options will appear.\n",
    "1. Click \"HDInsight cluster dashboard\". A new window will load.\n",
    "1. In the menu at left, click \"Spark2\".\n",
    "1. In the main window, click on the \"Configs\" tab.\n",
    "1. Scroll down to the \"Custom spark2-defaults\" option and expand its dropdown by clicking on the label (or triange beside it).\n",
    "1. Find the `spark.yarn.appMasterEnv.PYSPARK3_PYTHON` entry in the dropdown list. Change its path to the following:\n",
    "\n",
    "    `/usr/bin/anaconda/envs/cntk-py35/bin/python`<br/><br/>\n",
    "    \n",
    "1. Click on the green \"Save\" button that appears at upper right.\n",
    "1. When prompted, click the orange \"Restart\" button and select \"Restart all affected\".\n",
    "1. When the restart concludes, close the window. This will return you to a pane of dashboard options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"pyspark\"></a>\n",
    "## Image scoring with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cntk\"></a>\n",
    "### Cognitive Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tf\"></a>\n",
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
