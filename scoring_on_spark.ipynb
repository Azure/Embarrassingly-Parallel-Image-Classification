{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring images on Spark\n",
    "\n",
    "This notebook illustrates how trained Cognitive Toolkit (CNTK) and TensorFlow models can be applied to large image collections using PySpark. For more detail on image set creation and model training, please see the rest of the [Embarrassingly Parallel Image Classification](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification) repository.\n",
    "\n",
    "## Outline\n",
    "- [Setting up a Microsoft HDInsight Spark cluster and Azure Data Lake Store](#setup)\n",
    "   - [Provisioning the resources](#provision)\n",
    "   - [Transferring the image set](#transfer)\n",
    "   - [Installing Cognitive Toolkit and Tensorflow](#install)\n",
    "- [Image scoring with PySpark](#pyspark)\n",
    "   - [Cognitive Toolkit](#cntk)\n",
    "   - [TensorFlow](#tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "## Setting up a Microsoft HDInsight Spark cluster and associated Azure Data Lake Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"provision\"></a>\n",
    "### Provisioning the resources\n",
    "\n",
    "#### Azure Data Lake Store\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "   <img src=\"./img/spark_adls_provisioning/new_resource_button.gif\" width=\"100 px\"/>\n",
    "1. In the search field that appears, enter \"Data Lake Store\" and press Enter.\n",
    "   <img src=\"./img/spark_adls_provisioning/resource_search_box_adls.gif\" width=\"200 px\"/>\n",
    "\n",
    "1. In the search results, click on the \"Data Lake Store\" option published by Microsoft.\n",
    "   <img src=\"./img/spark_adls_provisioning/resource_search_result_adls.gif\" width=\"400 px\"/>\n",
    "\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the Data Lake Store resource type.\n",
    "   <img src=\"./img/spark_adls_provisioning/create.gif\" width=\"100 px\"/>\n",
    "1. Choose a unique name, subscription, resource group, and location for your Data Lake Store. Note the location: you will need to use the same location when deploying the Spark cluster.\n",
    "1. Select the appropriate pricing plan for your needs. (We recommend \"Pay-as-you-go\"; the tutorial will use <1 TB of data.)\n",
    "1. Click the \"Create\" button at the bottom of the pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Azure HDInsight Spark Cluster\n",
    "1. After logging into [Azure Portal](https://ms.portal.azure.com), click the \"+ New\" button near the upper left to create a new resource.\n",
    "   <img src=\"./img/spark_adls_provisioning/new_resource_button.gif\" width=\"100 px\"/>\n",
    "1. In the search field that appears, enter \"HDInsight\" and press Enter.\n",
    "   <img src=\"./img/spark_adls_provisioning/resource_search_box.gif\" width=\"200 px\"/>\n",
    "\n",
    "1. In the search results, click on the \"HDInsight\" option published by Microsoft.\n",
    "   <img src=\"./img/spark_adls_provisioning/resource_search_result.gif\" width=\"400 px\"/>\n",
    "\n",
    "1. Click the \"Create\" button at the bottom of the new pane that opens to describe the HDInsight resource type.\n",
    "   <img src=\"./img/spark_adls_provisioning/create.gif\" width=\"100 px\"/>\n",
    "1. In the \"Basics\" section of the \"New HDInsight cluster\" pane:\n",
    "    1. Choose a unique cluster name and the appropriate subscription.\n",
    "    1. Click on \"Cluster configuration\" to load a pane of settings.\n",
    "       1. Set the cluster type to \"Spark\".\n",
    "       1. Set the version to \"Spark 2.0.2 (HDI 3.5)\".\n",
    "       <img src=\"./img/spark_adls_provisioning/cluster_type_settings.gif\" width=\"400 px\"/>\n",
    "       1. Click the \"Select\" button at the bottom of the pane.\n",
    "    1. Choose a password for the `admin` account. You will use this account to log into Jupyter Notebook later in the walkthrough.\n",
    "    1. Select the resource group and location where your Data Lake Store is located.\n",
    "    1. Click the \"Next\" button at the bottom of the pane.\n",
    "1. In the \"Storage\" section of the \"New HDInsight cluster\" pane:\n",
    "   1. Ensure that \"Data Lake Store\" is selected for the \"Primary storage type\".\n",
    "   1. Click on \"Select Data Lake Storage Account\" to load a pane of settings.\n",
    "       1. Under \"Select a storage account\", select your ADLS.\n",
    "       1. Click on \"Configure Data Lake Access\" to load a pane of settings.\n",
    "           1. Create a new service principal.\n",
    "           1. Click on \"Access\" to load a pane of settings.\n",
    "               1. Under \"Select File Permissions\", click the box to the left of your ADLS name. (The box may be obscured until mouseover.). Click \"Select\".\n",
    "               1. Under \"Assign Selected Permissions\", click \"Run\".\n",
    "               1. When the run completes, click \"Done\".\n",
    "       1. Click the \"Next\" button at the bottom of the pane.\n",
    "1. In the \"Summary\" section of the \"New HDInsight cluster\" pane:\n",
    "   1. If desired, you can edit the cluster size settings to choose node counts/sizes based on your budget and time constraints. This tutorial can be completed using a cluster with **4** worker nodes and a node size of **D12 v2** (for both worker and head nodes). For more information, please see the [cluster](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters) and [VM](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-linux-sizes#dv2-series) size guides.\n",
    "1. Click the \"Create\" button at the bottom of the pane.\n",
    "\n",
    "#### Checking cluster deployment status\n",
    "\n",
    "Cluster deployment may take approximately twenty minutes. (We recommend transferring your image set to the ADLS while you wait; see the next section.) Cluster deployment status can be checked as follows:\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. During deployment, a blue bar will appear across the top of the overview pane with the title \"Applying changes\". When this bar disappears, deployment is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"transfer\"></a>\n",
    "### Transferring the image set\n",
    "\n",
    "Our evaluation image set was creating on a Data Science Virtual Machine. To transfer these images to our Azure Data Lake Store, we first copied the images to Azure Blob Storage using [AzCopy](https://docs.microsoft.com/en-gb/azure/storage/storage-use-azcopy), then to the Azure Data Lake Store with [AdlCopy](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob). After following the instructions linked above to download and install AzCopy/AdlCopy, we transferred the files with the following shell commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_image_dir = 'E:\\\\combined\\\\test'\n",
    "blob_account_name = ''\n",
    "blob_account_key = ''\n",
    "blob_account_container = 'test'\n",
    "adl_account_name = ''\n",
    "adl_account_folder = 'test'\n",
    "\n",
    "commands = '''\n",
    "AzCopy /Source:{0} /Dest:https://{1}.blob.core.windows.net/{2} /DestKey:{3} /S\n",
    "AdlCopy /source https://{1}.blob.core.windows.net/{2}/ /dest swebhdfs://{4}.azuredatalakestore.net/{5}/ /sourcekey {3}\n",
    "'''.format(local_image_dir, blob_account_name, blob_account_container,\n",
    "           blob_account_key, adl_account_name, adl_account_folder)\n",
    "\n",
    "print(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"install\"></a>\n",
    "### Installing Cognitive Toolkit and Tensorflow\n",
    "\n",
    "#### Obtaining and (optionally) modifying the script action\n",
    "\n",
    "We will install Cognitive Toolkit and Tensorflow on all head and worker nodes via Script Action. We have included a sample script action in the `scoring` subdirectory of [the Embarrassingly Parallel Image Classification git repository](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification), reproduced below for your convenience:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#\n",
    "# This install script generously shared by Miruna Oprescu\n",
    "# (then lightly modified by Mary Wahl), Microsoft Corporation, 2017\n",
    "\n",
    "cntk_home=\"/usr/hdp/current\"\n",
    "cd $cntk_home\n",
    "curl \"BinaryDrop/CNTK-2-0-beta10-0-Linux-64bit-CPU-Only.tar.gz\" | tar xzf -\n",
    "cd ./cntk/Scripts/install/linux \n",
    "sed -i \"s#\"ANACONDA_PREFIX=\\\"\\$HOME/anaconda3\\\"\"#\"ANACONDA_PREFIX=\\\"\\/usr/bin/anaconda\\\"\"#g\" install-cntk.sh\n",
    "sed -i \"s#\"\\$HOME/anaconda3\"#\"\\$ANACONDA_PREFIX\"#g\" install-cntk.sh\n",
    "./install-cntk.sh --py-version 35\n",
    "\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install pillow\n",
    "sudo /usr/bin/anaconda/envs/cntk-py35/bin/pip install tensorflow\n",
    "\n",
    "sudo mkdir /tmp/resnet\n",
    "cd /tmp/resnet\n",
    "wget https://mawahstorage.blob.core.windows.net/models/tf.zip -P /tmp/resnet\n",
    "unzip /tmp/resnet/tf.zip\n",
    "wget https://mawahstorage.blob.core.windows.net/models/resnet20_237_improvedpreprocessing.dnn -P /tmp/resnet\n",
    "sudo chmod -R 777 /tmp/resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above installed CNTK 2.0 beta release 10. As of this writing, other CNTK releases can be substituted as follows:\n",
    "1. Navigate to the [CNTK Releases](https://github.com/Microsoft/CNTK/releases) page\n",
    "1. Click on the appropriate release's link for a Linux, CPU Only release.\n",
    "1. After reading and agreeing to the mentioned licenses, copy the URL linked to the \"I accept\" button (e.g. from the page source) and paste over the URL in the `curl` command above.\n",
    "\n",
    "#### Running the script action\n",
    "\n",
    "After HDInsight cluster deployment finishes, run the script action to install CNTK as follows:\n",
    "1. Obtain the URI for the script action.\n",
    "   - If using the unmodified version in this git repo, ensure that your URI points to the \"raw\" file (not a webpage-embedded file).\n",
    "   - If you have modified the script action, upload it to the website or Azure Blob Storage account of your choice and note its URI.\n",
    "1. Click on the \"Search Resources\" magnifying glass icon along the top bar of [Azure Portal](https://ms.portal.azure.com).\n",
    "1. Type in the name of your HDInsight cluster and click on its entry in the resulting drop-down list. The overview pane for your HDInsight cluster will appear.\n",
    "1. In the search field at upper left, type in \"Script actions\". Click the \"Script actions\" option in the results list.\n",
    "1. Click the \"+ Submit new\" button along the top of the Script Actions pane. A new pane of options will appear.\n",
    "   1. Under name, type \"install\" (without the quotes).\n",
    "   1. Under \"Bash script URI\", type in the URI.\n",
    "   1. Ensure that \"Head\" and \"Worker\" boxes are checked.\n",
    "   1. Click the \"Create\" button along the bottom of the pane.\n",
    "   \n",
    "Expect the script action to take roughly fifteen minutes to run.\n",
    "   \n",
    "#### Updating the Python 3 path\n",
    "\n",
    "The script action above installed Cognitive Toolkit and Tensorflow under a new Python environment, `cntk-py35`. Follow the steps below to direct PySpark to use this new environment:\n",
    "\n",
    "1. Navigate back to the HDInsight cluster's overview pane by clicking \"Overview\" near the upper left of the pane.\n",
    "1. Under \"Quick links\" in the main window, click the \"Cluster dashboards\" button. A new pane of dashboard options will appear.\n",
    "1. Click \"HDInsight cluster dashboard\". A new window will load.\n",
    "1. In the menu at left, click \"Spark2\".\n",
    "1. In the main window, click on the \"Configs\" tab.\n",
    "1. Scroll down to the \"Custom spark2-defaults\" option and expand its dropdown by clicking on the label (or triange beside it).\n",
    "1. Find the `spark.yarn.appMasterEnv.PYSPARK3_PYTHON` entry in the dropdown list. Change its path to the following:\n",
    "\n",
    "    `/usr/bin/anaconda/envs/cntk-py35/bin/python`<br/><br/>\n",
    "    \n",
    "1. Click on the green \"Save\" button that appears at upper right.\n",
    "1. When prompted, click the orange \"Restart\" button and select \"Restart all affected\".\n",
    "1. When the restart concludes, close the window. This will return you to a pane of dashboard options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"pyspark\"></a>\n",
    "## Image scoring with PySpark\n",
    "\n",
    "### Define functions/variables/RDDs used by both scoring pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1486565576928_0061</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-mawaht.h2celvvrkkmuregxlpjd0qjune.cx.internal.cloudapp.net:8088/proxy/application_1486565576928_0061/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.16:30060/node/containerlogs/container_1486565576928_0061_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "def get_nlcd_id(my_filename):\n",
    "    ''' Extracts the true label  '''\n",
    "    folder, _ = os.path.split(my_filename)\n",
    "    return(int(os.path.basename(folder)))\n",
    "\n",
    "adls_name = 'mawahtensorflow'\n",
    "adls_folder = 'test'\n",
    "n_workers = 4\n",
    "local_tmp_dir = '/tmp/resnet'\n",
    "\n",
    "dataset_dir = 'adl://{}.azuredatalakestore.net/{}'.format(adls_name, adls_folder)\n",
    "image_rdd = sc.binaryFiles('{}/*/*.png'.format(dataset_dir), minPartitions=n_workers).coalesce(n_workers)\n",
    "\n",
    "# Define correspondence of NLCD ids to labels of the trained model\n",
    "nlcd_id_to_group = {21: 'Developed',\n",
    "                    22: 'Developed',\n",
    "                    23: 'Developed',\n",
    "                    24: 'Developed',\n",
    "                    11: 'Water/Wetlands',\n",
    "                    12: 'Water/Wetlands',\n",
    "                    95: 'Water/Wetlands',\n",
    "                    41: 'Forest',\n",
    "                    42: 'Forest',\n",
    "                    43: 'Forest',\n",
    "                    90: 'Forest',\n",
    "                    31: 'Barren',\n",
    "                    51: 'Shrubland',\n",
    "                    52: 'Shrubland',\n",
    "                    71: 'Grassland',\n",
    "                    72: 'Grassland',\n",
    "                    73: 'Grassland',\n",
    "                    74: 'Grassland',\n",
    "                    81: 'Cultivated',\n",
    "                    82: 'Cultivated'}\n",
    "group_to_label = {'Shrubland': 0,\n",
    "                  'Forest': 1,\n",
    "                  'Cultivated': 2,\n",
    "                  'Barren': 3,\n",
    "                  'Water/Wetlands': 4,\n",
    "                  'Grassland': 5,\n",
    "                  'Developed': 6}\n",
    "\n",
    "nlcd_id_to_label = {key: group_to_label[nlcd_id_to_group[key]] for key in nlcd_id_to_group.keys()}\n",
    "nlcd_id_to_label_bc = sc.broadcast(nlcd_id_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cntk\"></a>\n",
    "### Score and evaluate with a trained Cognitive Toolkit (CNTK) model\n",
    "\n",
    "#### Make the trained CNTK model available to all workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cntk import load_model\n",
    "\n",
    "cntk_model_filepath = '{}/resnet20_237_improvedpreprocessing.dnn'.format(local_tmp_dir)\n",
    "cntk_model_filepath_bc = sc.broadcast(cntk_model_filepath)\n",
    "sc.addFile(cntk_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions to be run by worker nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cntk_get_preprocessed_image(my_file):\n",
    "    ''' Perform reshaping '''\n",
    "    image_data = np.array(Image.open(my_file), dtype=np.float32)\n",
    "    image_data = np.ascontiguousarray(np.transpose(image_data, (2, 0, 1)))\n",
    "    return(image_data)\n",
    "\n",
    "def argsoftmax(x):\n",
    "    ''' Apply softmax, then return the best label '''\n",
    "    exponentiated = np.exp(x)\n",
    "    softmax = exponentiated / exponentiated.sum(axis=0)\n",
    "    return(np.argmax(softmax))\n",
    "\n",
    "def cntk_run_worker(files):\n",
    "    ''' Scoring script run by each worker '''\n",
    "    cntk_model_filepath = cntk_model_filepath_bc.value\n",
    "    loaded_model = load_model(SparkFiles.get(cntk_model_filepath))\n",
    "    nlcd_id_to_label = nlcd_id_to_label_bc.value\n",
    "    \n",
    "    # Iterate through the files. The first value in each tuple is the file name; the second is the image data\n",
    "    for file in files:\n",
    "        preprocessed_image = cntk_get_preprocessed_image(BytesIO(file[1]))\n",
    "        dnn_output = loaded_model.eval({loaded_model.arguments[0]: [preprocessed_image]})\n",
    "        true_label = nlcd_id_to_label[get_nlcd_id(file[0])]\n",
    "        yield (file[0], true_label, argsoftmax(np.squeeze(dnn_output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score all test set images with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_images = image_rdd.mapPartitions(cntk_run_worker)\n",
    "\n",
    "start = pd.datetime.now()\n",
    "cntk_results = labeled_images.collect()\n",
    "print('Scored {} images'.format(len(results)))\n",
    "stop = pd.datetime.now()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cntk_df = pd.DataFrame(cntk_results, columns=['filename', 'true_label', 'predicted_label'])\n",
    "num_correct = sum(cntk_df['true_label'] == cntk_df['predicted_label'])\n",
    "num_total = len(cntk_results)\n",
    "print('Correctly predicted {} of {} images ({:0.2f}%)'.format(num_correct, num_total, 100 * num_correct / num_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tf\"></a>\n",
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the trained Tensorflow model available to all workers\n",
    "\n",
    "Loads a slightly modified version of the tf-slim ResNet definition from the Tensorflow models git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.addPyFile(os.path.join(local_tmp_dir, 'resnet_utils.py'))\n",
    "sc.addPyFile(os.path.join(local_tmp_dir, 'resnet_v1.py'))\n",
    "model_dir_bc = sc.broadcast(local_tmp_dir)\n",
    "\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import resnet_v1\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions used by workers for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_network_fn(num_classes, weight_decay=0.0, is_training=False):\n",
    "    arg_scope = resnet_v1.resnet_arg_scope(weight_decay=weight_decay)\n",
    "    func = resnet_v1.resnet_v1_50\n",
    "    @functools.wraps(func)\n",
    "    def network_fn(images):\n",
    "        with slim.arg_scope(arg_scope):\n",
    "            return func(images, num_classes, is_training=is_training)\n",
    "    if hasattr(func, 'default_image_size'):\n",
    "        network_fn.default_image_size = func.default_image_size\n",
    "    return(network_fn)\n",
    "\n",
    "def mean_image_subtraction(image, means):\n",
    "    num_channels = image.get_shape().as_list()[-1]\n",
    "    channels = tf.split(2, num_channels, image)\n",
    "    for i in range(num_channels):\n",
    "        channels[i] -= means[i]\n",
    "    return(tf.concat(2, channels))\n",
    "\n",
    "def get_preprocessing():\n",
    "    def preprocessing_fn(image, output_height=224, output_width=224):\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        resized_image = tf.image.resize_bilinear(image, [output_height, output_width], align_corners=False)\n",
    "        resized_image = tf.squeeze(resized_image)\n",
    "        resized_image.set_shape([output_height, output_width, 3])\n",
    "        image = tf.to_float(resized_image)\n",
    "        return(mean_image_subtraction(image, [123.68, 116.78, 103.94]))\n",
    "    return(preprocessing_fn)\n",
    "\n",
    "def tf_run_worker(files):\n",
    "    nlcd_id_to_label = nlcd_id_to_label_bc.value\n",
    "    model_dir = model_dir_bc.value\n",
    "    class_count = 7\n",
    "    results = []\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        network_fn = get_network_fn(num_classes=class_count, is_training=False)\n",
    "        image_preprocessing_fn = get_preprocessing()\n",
    "        \n",
    "        current_image = tf.placeholder(tf.uint8, shape=(224, 224, 3))\n",
    "        preprocessed_image = image_preprocessing_fn(current_image, 224, 224)\n",
    "        image  = tf.expand_dims(preprocessed_image, 0)\n",
    "        logits, _ = network_fn(image)\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            my_saver = tf.train.Saver()\n",
    "            my_saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
    "            \n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            try:\n",
    "                for file in files:\n",
    "                    imported_image_np = np.asarray(Image.open(BytesIO(file[1])), dtype=np.uint8)\n",
    "                    result = sess.run(predictions, feed_dict={current_image: imported_image_np})\n",
    "                    true_label = nlcd_id_to_label[get_nlcd_id(file[0])]\n",
    "                    results.append([file[0], true_label, result[0]])\n",
    "            finally:\n",
    "                coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score all images with trained Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_images_tf = image_rdd.mapPartitions(tf_run_worker)\n",
    "\n",
    "start = pd.datetime.now()\n",
    "results_tf = labeled_images_tf.collect()\n",
    "print('Scored {} images'.format(len(results_tf)))\n",
    "stop = pd.datetime.now()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame(results_tf, columns=['filename', 'true_label', 'predicted_label'])\n",
    "num_correct = sum(tf_df['true_label'] == tf_df['predicted_label'])\n",
    "num_total = len(results_tf)\n",
    "print('Correctly predicted {} of {} images ({:0.2f}%)'.format(num_correct, num_total, 100 * num_correct / num_total))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
